{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["-JwoFcqL9FBc","YMbIaiSiNkz1","rTLjZJ-JNVu0","CrQjfYxwN8KX","Qz34p3i1OA3R","3SSkgD37OHm3"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Drive Mount"],"metadata":{"id":"YMbIaiSiNkz1"}},{"cell_type":"code","source":["#êµ¬ê¸€ë“œë¼ì´ë¸Œ ì—°ë™\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5jgtilUKhgQn","outputId":"1161b1a0-3b9b-4d8f-f033-f4080c1c7371","executionInfo":{"status":"ok","timestamp":1676038963344,"user_tz":-540,"elapsed":24877,"user":{"displayName":"JIN","userId":"06208610298616237541"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Install (streamlit, kobert)"],"metadata":{"id":"-JwoFcqL9FBc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qONxoJQ18iuJ"},"outputs":[],"source":["!pip install streamlit -q\n","!pip install streamlit-folium\n","!pip install pyngrok\n","\n","!pip install mxnet\n","!pip install gluonnlp tqdm\n","!pip install sentencepiece\n","!pip install transformers\n","!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"]},{"cell_type":"markdown","source":["# Ngrok Personal Token\n","https://ngrok.com/"],"metadata":{"id":"rTLjZJ-JNVu0"}},{"cell_type":"code","source":["from pyngrok import ngrok\n","\n","ngrok.set_auth_token('2LY49GRFmGE8RlEm9XboXIZyFwu_6fUcBvkG5ZJy7yM8U3VSL')"],"metadata":{"id":"XZ766ErF9i8i","executionInfo":{"status":"ok","timestamp":1676039621092,"user_tz":-540,"elapsed":4585,"user":{"displayName":"JIN","userId":"06208610298616237541"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4308acbb-2e51-4855-c1e0-b7d33ff24d07"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":[]}]},{"cell_type":"markdown","source":["# Connect Page(Compose)\n","Make .Py(Connect stremlit)\n","py ì €ì¥í•˜ê³  streamlit ì›¹ì—ì„œ reload\n","\n","ì½”ë“œ ìˆ˜ì •í• ë–„ : *%%writefile app.py* --> ì£¼ì„ì²˜ë¦¬ í•´ì•¼ ì½”ë“œë§ˆë‹¤ ìƒ‰ê¹” ë³´ì„"],"metadata":{"id":"kn285XHLNnh6"}},{"cell_type":"code","source":["%%writefile app2.py\n","\n","import streamlit as st\n","import streamlit.components.v1 as html\n","import numpy as np\n","import pandas as pd\n","import requests\n","import folium\n","from folium.plugins import MiniMap\n","from streamlit_folium import st_folium\n","\n","# torch\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","\n","# kobert\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","\n","#transformers\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","\n","# í˜ì´ì§€ì˜ ê¸°ë³¸ ì„¤ì • êµ¬ì„±\n","st.set_page_config(\n"," layout=\"wide\",\n"," page_title='ì˜¤ëŠ˜ ì´ê±° ë¨¹ì–´')\n","\n","#######################################################################################################\n","#### ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ####\n","\n","device = torch.device(\"cuda:0\") #GPUì‚¬ìš©\n","#device = torch.device(\"cpu\")  #CPUì‚¬ìš©\n","\n","bertmodel, vocab = get_pytorch_kobert_model()\n","\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n","\n","class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))\n","\n","max_len = 64\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 20\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5\n","\n","class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=17,\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","\n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device), return_dict=False)\n","\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)\n","\n","model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n","\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0} ]\n","\n","optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","def calc_accuracy(X,Y):\n","    max_vals, max_indices = torch.max(X, 1)\n","    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","    return train_acc\n","\n","def softmax(vals, idx):\n","    valscpu = vals.detach().cpu().squeeze(0)\n","    a = 0\n","    for i in valscpu:\n","        a += np.exp(i)\n","    return ((np.exp(valscpu[idx]))/a).item() * 100\n","\n","\n","def testModel(model, seq):\n","    cate = [\"ê³±ì°½\",\"êµ­ìˆ˜\",\"ëˆì¹´ì¸ \", \"ë””ì €íŠ¸\",\"ë¼ë©˜\",\"ë²„ê±°\", \"ë² ì´ì»¤ë¦¬\", \"ë¶„ì‹\", \"ìŠ¤ì‹œ\", \"ì•„ì‹œì•„ìŒì‹\", \"ì–‘ì‹\", \"ì „ê³¨\", \"ì¤‘ì‹\", \"ì¹˜í‚¨\", \"íƒ€ì½”\", \"í•œì‹\", \"í•´ì‚°ë¬¼\"]\n","    tmp = [seq]\n","    transform = nlp.data.BERTSentenceTransform(tok, max_len, pad=True, pair=False)\n","    tokenized = transform(tmp)\n","\n","    modelload.eval()\n","    result = modelload(torch.tensor([tokenized[0]]).to(device), [tokenized[1]], torch.tensor(tokenized[2]).to(device)) \n","    idx = result.argmax().cpu().item() #ì¶œë ¥ì˜ ìµœëŒ€ê°’ì´ ë‚˜ì˜¤ê²Œí•¨\n","    result2 = F.softmax(result, dim=1).sort() #ê° ê°’ì— ëŒ€í•œ softmaxí•¨ìˆ˜ ì ìš©\n","\n","    #return cate[idx], softmax(result,idx)\n","    return cate[result2[1][0][-1]],round((result2[0][0][-1]).item(), 4)*100, cate[result2[1][0][-2]],round((result2[0][0][-2]).item(), 4)*100, cate[result2[1][0][-3]],round((result2[0][0][-3]).item(), 4)*100\n","\n","# ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ í•œë²ˆë§Œ ë¡œë“œí•˜ê³  ìºì‹œì— ì €ì¥í•˜ê¸°\n","@st.cache_resource\n","def cache_model(path, modelname):\n","    #modelload = torch.load(\"/content/drive/MyDrive/Colab Notebooks/Save_data/á„†á…©á„ƒá…¦á†¯á„‡á…®á†«á„‰á…¥á†¨/á„á…©á„‡á…¥á„á…³/model6.pt\", map_location=torch.device('cpu')) # cpuì‚¬ìš©ì‹œ\n","    modelload = torch.load(\"/content/drive/MyDrive/Colab Notebooks/Save_data/á„†á…©á„ƒá…¦á†¯á„‡á…®á†«á„‰á…¥á†¨/á„á…©á„‡á…¥á„á…³/model6.pt\") # gpuì‚¬ìš©ì‹œ\n","    modelload.eval()\n","    return modelload\n","\n","modelload = cache_model('/content/drive/MyDrive/Colab Notebooks/Save_data/á„†á…©á„ƒá…¦á†¯á„‡á…®á†«á„‰á…¥á†¨/á„á…©á„‡á…¥á„á…³/','model6.pt')\n","\n","# ì¹´ì¹´ì˜¤ api\n","@st.cache_resource\n","def elec_location(region,page_num):\n","    url = 'https://dapi.kakao.com/v2/local/search/keyword.json'\n","    params = {'query': region,'page': page_num, 'sort' : 'popularity'}\n","    headers = {\"Authorization\": \"KakaoAK 6dd31dbd3f7b90aed3f5591fdde29527\"}\n","\n","    places = requests.get(url, params=params, headers=headers).json()['documents']\n","\n","    return places\n","\n","def elec_info(places):\n","    X = []\n","    Y = []\n","    stores = []\n","    road_address = []\n","    phone = []\n","    place_url = []\n","    ID = []\n","    for place in places:\n","        X.append(float(place['x']))\n","        Y.append(float(place['y']))\n","        stores.append(place['place_name'])\n","        road_address.append(place['road_address_name'])\n","        phone.append(place['phone'])\n","        place_url.append(place['place_url'])\n","        ID.append(place['id'])\n","\n","    ar = np.array([ID,stores, X, Y, road_address, phone, place_url]).T\n","    df = pd.DataFrame(ar, columns = ['ID','stores', 'X', 'Y','road_address','phone','place_url'])\n","    return df\n","\n","def keywords(location_name):\n","    df = None\n","    page_num = int(1)\n","    for loca in location_name:\n","        for page in range(1,page_num+1):\n","            local_name = elec_location(loca, page)\n","            local_elec_info = elec_info(local_name)\n","\n","            if df is None:\n","                df = local_elec_info\n","            elif local_elec_info is None:\n","                continue\n","            else:\n","                df = pd.concat([df, local_elec_info],join='outer', ignore_index = True)\n","    return df\n","\n","def make_map(dfs, m):\n","    \n","    minimap = MiniMap() \n","    m.add_child(minimap)\n","\n","    for i in range(len(dfs)):\n","        folium.Marker([dfs['Y'][i],dfs['X'][i]],\n","                      tooltip=dfs['stores'][i],\n","                      popup = '<iframe width=\"800\" height=\"400\" src=\"' + df['place_url'][i] + '\"title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay;  clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>',\n","                      ).add_to(m)\n","    return m\n","\n","#######################################################################################################\n","\n","st.sidebar.header('Side Menu')\n","tab1, tab2 = st.tabs(['search', 'map'])\n","\n","# user ì…ë ¥ê°’ ì €ì¥\n","if 'user_input' not in st.session_state:\n","    st.session_state['user_input'] = ''\n","\n","if 'user_location_input' not in st.session_state:\n","    st.session_state['user_location_input'] = ''\n","\n","with st.sidebar:\n","        when = st.selectbox('ì‹ì‚¬ ì‹œê°„ì€ ì–¸ì œì¸ê°€ìš”?', ['ì•„ì¹¨', 'ì ì‹¬', 'ì €ë…'])\n","        #location = st.text_input('ì§€ê¸ˆ ê³„ì‹  ì§€ì—­ì€ ì–´ë””ì¸ê°€ìš”?', value = '', placeholder = 'ê·¼ì²˜ ì§€í•˜ì²  ì—­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”', key='user_location_input')\n","\n","with tab1:\n","    st.subheader('ğŸ’­ì˜¤ëŠ˜ë„ ë¬´ì—‡ì„ ë¨¹ì„ì§€ ê³ ë¯¼í•˜ê³  ê³„ì‹ ê°€ìš”?')\n","\n","    value = st.text_area('ì§€ê¸ˆ ìƒê°ë‚˜ëŠ” í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ê³  Ctrl+Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!', placeholder = 'Ex) ìœ¡ì¦™ì´ íŒ¡íŒ¡ í„°ì§€ëŠ” ê³ ì†Œí•œ ìŒì‹ì´ ë¨¹ê³ ì‹¶ì–´.', key='user_input')\n","    cat1,val1, cat2,val2, cat3,val3 = testModel(model ,st.session_state.user_input)\n","\n","    if value:\n","       st.header(cat1, 'ì´ ìŒì‹ì€ ì–´ë– ì‹ ê°€ìš”?')\n","\n","       st.subheader(f\"{cat1}ì´(ê°€) ê°€ì¥ ì í•©í•œ ìŒì‹ì…ë‹ˆë‹¤. ì‹ ë¢°ë„ëŠ” {round(val1, 2)}% ì…ë‹ˆë‹¤.\")\n","       #st.write(cat1, 'ì´(ê°€) ê°€ì¥ ì í•©í•œ ìŒì‹ì…ë‹ˆë‹¤.', 'ì‹ ë¢°ë„ëŠ”', round(val1, 2), '% ì…ë‹ˆë‹¤.')\n","\n","       st.write('ì…ë ¥ë¬¸ì¥ê³¼ ê°€ì¥ ì¼ì¹˜í•˜ëŠ” ìŒì‹ TOP3 ì…ë‹ˆë‹¤.')\n","       st.write('ğŸ¥‡',cat1, 'ì‹ ë¢°ë„ëŠ”', round(val1, 2),'% ì…ë‹ˆë‹¤.')\n","       st.write('ğŸ¥ˆ',cat2, 'ì‹ ë¢°ë„ëŠ”', round(val2, 2),'% ì…ë‹ˆë‹¤.')\n","       st.write('ğŸ¥‰',cat3, 'ì‹ ë¢°ë„ëŠ”', round(val3, 2),'% ì…ë‹ˆë‹¤.')\n","\n","\n","with tab2:\n","    st.subheader('ğŸš‡ê°€ì‹œë ¤ëŠ” ì§€ì—­ì´ ì–´ë””ì¸ê°€ìš”?')\n","    location = st.text_input('ì§€í•˜ì² ì—­ì„ ê¸°ë°˜ìœ¼ë¡œ ìŒì‹ì ì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.', value = '', placeholder = 'ê·¼ì²˜ ì§€í•˜ì²  ì—­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”', key='user_location_input')\n","    user_location = st.session_state.user_location_input\n","\n","    if location:\n","        kakao_location = [user_location + ' ' + cat1]\n","        try:\n","          df = keywords(kakao_location)\n","          lat = 0\n","          lon = 0\n","          for i in df['Y']:\n","              lat += float(i)\n","          for j in df['X']:\n","              lon += float(j)\n","          lat = lat/len(df['Y'])\n","          lon = lon/len(df['X'])\n","          m = folium.Map(kakao_location=[lat, lon],   # ê¸°ì¤€ì¢Œí‘œ: current_location\n","                        zoom_start=16)\n","          make_map = make_map(df, m)\n","          st_folium(make_map, width = 1000, height = 500, zoom=16, center = [lat, lon])\n","          df = df.drop(columns = ['ID', 'X', 'Y'])\n","          st.dataframe(df)\n","          st.write('ê²°ê³¼ëŠ” ì¸ê¸°ë„ìˆœìœ¼ë¡œ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.')\n","        except:\n","          st.write('ì•„ì‰½ê²Œë„ ' + user_location + ' ê·¼ì²˜ì—ëŠ” ' + cat1 + ' ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤ã… ã… ')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8GOkWNdSmpbI","outputId":"cf04ace8-458f-4324-a941-9258107f4f26","executionInfo":{"status":"ok","timestamp":1676039823293,"user_tz":-540,"elapsed":453,"user":{"displayName":"JIN","userId":"06208610298616237541"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app2.py\n"]}]},{"cell_type":"code","source":["!cat app2.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j7swO3uYtHgY","outputId":"9049363d-9170-430e-fc66-72c02a375e02","executionInfo":{"status":"ok","timestamp":1676039670069,"user_tz":-540,"elapsed":4,"user":{"displayName":"JIN","userId":"06208610298616237541"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","import streamlit as st\n","import streamlit.components.v1 as html\n","import numpy as np\n","import pandas as pd\n","import requests\n","import folium\n","from folium.plugins import MiniMap\n","from streamlit_folium import st_folium\n","\n","# torch\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","\n","# kobert\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","\n","#transformers\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","\n","# í˜ì´ì§€ì˜ ê¸°ë³¸ ì„¤ì • êµ¬ì„±\n","st.set_page_config(\n"," layout=\"wide\",\n"," page_title='ì˜¤ëŠ˜ ì´ê±° ë¨¹ì–´')\n","\n","#######################################################################################################\n","#### ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ####\n","\n","device = torch.device(\"cuda:0\") #GPUì‚¬ìš©\n","#device = torch.device(\"cpu\")  #CPUì‚¬ìš©\n","\n","bertmodel, vocab = get_pytorch_kobert_model()\n","\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n","\n","class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))\n","\n","max_len = 64\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 20\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5\n","\n","class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=17,\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","\n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device), return_dict=False)\n","\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)\n","\n","model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n","\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0} ]\n","\n","optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","def calc_accuracy(X,Y):\n","    max_vals, max_indices = torch.max(X, 1)\n","    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","    return train_acc\n","\n","def softmax(vals, idx):\n","    valscpu = vals.detach().cpu().squeeze(0)\n","    a = 0\n","    for i in valscpu:\n","        a += np.exp(i)\n","    return ((np.exp(valscpu[idx]))/a).item() * 100\n","\n","\n","def testModel(model, seq):\n","    cate = [\"ê³±ì°½\",\"êµ­ìˆ˜\",\"ëˆì¹´ì¸ \", \"ë””ì €íŠ¸\",\"ë¼ë©˜\",\"ë²„ê±°\", \"ë² ì´ì»¤ë¦¬\", \"ë¶„ì‹\", \"ìŠ¤ì‹œ\", \"ì•„ì‹œì•„ìŒì‹\", \"ì–‘ì‹\", \"ì „ê³¨\", \"ì¤‘ì‹\", \"ì¹˜í‚¨\", \"íƒ€ì½”\", \"í•œì‹\", \"í•´ì‚°ë¬¼\"]\n","    tmp = [seq]\n","    transform = nlp.data.BERTSentenceTransform(tok, max_len, pad=True, pair=False)\n","    tokenized = transform(tmp)\n","\n","    modelload.eval()\n","    result = modelload(torch.tensor([tokenized[0]]).to(device), [tokenized[1]], torch.tensor(tokenized[2]).to(device)) \n","    idx = result.argmax().cpu().item() #ì¶œë ¥ì˜ ìµœëŒ€ê°’ì´ ë‚˜ì˜¤ê²Œí•¨\n","    result2 = F.softmax(result, dim=1).sort() #ê° ê°’ì— ëŒ€í•œ softmaxí•¨ìˆ˜ ì ìš©\n","\n","    #return cate[idx], softmax(result,idx)\n","    return cate[result2[1][0][-1]],round((result2[0][0][-1]).item(), 4)*100, cate[result2[1][0][-2]],round((result2[0][0][-2]).item(), 4)*100, cate[result2[1][0][-3]],round((result2[0][0][-3]).item(), 4)*100\n","\n","# ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ í•œë²ˆë§Œ ë¡œë“œí•˜ê³  ìºì‹œì— ì €ì¥í•˜ê¸°\n","@st.cache_resource\n","def cache_model(path, modelname):\n","    #modelload = torch.load(\"/content/drive/MyDrive/Colab Notebooks/Save_data/á„†á…©á„ƒá…¦á†¯á„‡á…®á†«á„‰á…¥á†¨/á„á…©á„‡á…¥á„á…³/model6.pt\", map_location=torch.device('cpu')) # cpuì‚¬ìš©ì‹œ\n","    modelload = torch.load(\"/content/drive/MyDrive/Colab Notebooks/Save_data/á„†á…©á„ƒá…¦á†¯á„‡á…®á†«á„‰á…¥á†¨/á„á…©á„‡á…¥á„á…³/model6.pt\") # gpuì‚¬ìš©ì‹œ\n","    modelload.eval()\n","    return modelload\n","\n","modelload = cache_model(\"/content/drive/MyDrive/Colab Notebooks/Save_data/á„†á…©á„ƒá…¦á†¯á„‡á…®á†«á„‰á…¥á†¨/á„á…©á„‡á…¥á„á…³/model6.pt\")\n","\n","# ì¹´ì¹´ì˜¤ api\n","@st.cache_resource\n","def elec_location(region,page_num):\n","    url = 'https://dapi.kakao.com/v2/local/search/keyword.json'\n","    params = {'query': region,'page': page_num, 'sort' : 'popularity'}\n","    headers = {\"Authorization\": \"KakaoAK 6dd31dbd3f7b90aed3f5591fdde29527\"}\n","\n","    places = requests.get(url, params=params, headers=headers).json()['documents']\n","\n","    return places\n","\n","def elec_info(places):\n","    X = []\n","    Y = []\n","    stores = []\n","    road_address = []\n","    phone = []\n","    place_url = []\n","    ID = []\n","    for place in places:\n","        X.append(float(place['x']))\n","        Y.append(float(place['y']))\n","        stores.append(place['place_name'])\n","        road_address.append(place['road_address_name'])\n","        phone.append(place['phone'])\n","        place_url.append(place['place_url'])\n","        ID.append(place['id'])\n","\n","    ar = np.array([ID,stores, X, Y, road_address, phone, place_url]).T\n","    df = pd.DataFrame(ar, columns = ['ID','stores', 'X', 'Y','road_address','phone','place_url'])\n","    return df\n","\n","def keywords(location_name):\n","    df = None\n","    page_num = int(1)\n","    for loca in location_name:\n","        for page in range(1,page_num+1):\n","            local_name = elec_location(loca, page)\n","            local_elec_info = elec_info(local_name)\n","\n","            if df is None:\n","                df = local_elec_info\n","            elif local_elec_info is None:\n","                continue\n","            else:\n","                df = pd.concat([df, local_elec_info],join='outer', ignore_index = True)\n","    return df\n","\n","def make_map(dfs, m):\n","    \n","    minimap = MiniMap() \n","    m.add_child(minimap)\n","\n","    for i in range(len(dfs)):\n","        folium.Marker([dfs['Y'][i],dfs['X'][i]],\n","                      tooltip=dfs['stores'][i],\n","                      popup = '<iframe width=\"800\" height=\"400\" src=\"' + df['place_url'][i] + '\"title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay;  clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>',\n","                      ).add_to(m)\n","    return m\n","\n","#######################################################################################################\n","\n","st.sidebar.header('Side Menu')\n","tab1, tab2 = st.tabs(['search', 'map'])\n","\n","# user ì…ë ¥ê°’ ì €ì¥\n","if 'user_input' not in st.session_state:\n","    st.session_state['user_input'] = ''\n","\n","if 'user_location_input' not in st.session_state:\n","    st.session_state['user_location_input'] = ''\n","\n","with st.sidebar:\n","        when = st.selectbox('ì‹ì‚¬ ì‹œê°„ì€ ì–¸ì œì¸ê°€ìš”?', ['ì•„ì¹¨', 'ì ì‹¬', 'ì €ë…'])\n","        #location = st.text_input('ì§€ê¸ˆ ê³„ì‹  ì§€ì—­ì€ ì–´ë””ì¸ê°€ìš”?', value = '', placeholder = 'ê·¼ì²˜ ì§€í•˜ì²  ì—­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”', key='user_location_input')\n","\n","with tab1:\n","    st.subheader('ğŸ’­ì˜¤ëŠ˜ë„ ë¬´ì—‡ì„ ë¨¹ì„ì§€ ê³ ë¯¼í•˜ê³  ê³„ì‹ ê°€ìš”?')\n","\n","    value = st.text_area('ì§€ê¸ˆ ìƒê°ë‚˜ëŠ” í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ê³  Ctrl+Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!', placeholder = 'Ex) ìœ¡ì¦™ì´ íŒ¡íŒ¡ í„°ì§€ëŠ” ê³ ì†Œí•œ ìŒì‹ì´ ë¨¹ê³ ì‹¶ì–´.', key='user_input')\n","    cat1,val1, cat2,val2, cat3,val3 = testModel(model ,st.session_state.user_input)\n","\n","    if value:\n","       st.header(cat1, 'ì´ ìŒì‹ì€ ì–´ë– ì‹ ê°€ìš”?')\n","\n","       st.subheader(f\"{cat1}ì´(ê°€) ê°€ì¥ ì í•©í•œ ìŒì‹ì…ë‹ˆë‹¤. ì‹ ë¢°ë„ëŠ” {round(val1, 2)}% ì…ë‹ˆë‹¤.\")\n","       #st.write(cat1, 'ì´(ê°€) ê°€ì¥ ì í•©í•œ ìŒì‹ì…ë‹ˆë‹¤.', 'ì‹ ë¢°ë„ëŠ”', round(val1, 2), '% ì…ë‹ˆë‹¤.')\n","\n","       st.write('ì…ë ¥ë¬¸ì¥ê³¼ ê°€ì¥ ì¼ì¹˜í•˜ëŠ” ìŒì‹ TOP3 ì…ë‹ˆë‹¤.')\n","       st.write('ğŸ¥‡',cat1, 'ì‹ ë¢°ë„ëŠ”', round(val1, 2),'% ì…ë‹ˆë‹¤.')\n","       st.write('ğŸ¥ˆ',cat2, 'ì‹ ë¢°ë„ëŠ”', round(val2, 2),'% ì…ë‹ˆë‹¤.')\n","       st.write('ğŸ¥‰',cat3, 'ì‹ ë¢°ë„ëŠ”', round(val3, 2),'% ì…ë‹ˆë‹¤.')\n","\n","\n","with tab2:\n","    st.subheader('ğŸš‡ê°€ì‹œë ¤ëŠ” ì§€ì—­ì´ ì–´ë””ì¸ê°€ìš”?')\n","    location = st.text_input('ì§€í•˜ì² ì—­ì„ ê¸°ë°˜ìœ¼ë¡œ ìŒì‹ì ì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.', value = '', placeholder = 'ê·¼ì²˜ ì§€í•˜ì²  ì—­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”', key='user_location_input')\n","    user_location = st.session_state.user_location_input\n","\n","    if location:\n","        kakao_location = [user_location + ' ' + cat1]\n","        try:\n","          df = keywords(kakao_location)\n","          lat = 0\n","          lon = 0\n","          for i in df['Y']:\n","              lat += float(i)\n","          for j in df['X']:\n","              lon += float(j)\n","          lat = lat/len(df['Y'])\n","          lon = lon/len(df['X'])\n","          m = folium.Map(kakao_location=[lat, lon],   # ê¸°ì¤€ì¢Œí‘œ: current_location\n","                        zoom_start=16)\n","          make_map = make_map(df, m)\n","          st_folium(make_map, width = 1000, height = 500, zoom=16, center = [lat, lon])\n","          df = df.drop(columns = ['ID', 'X', 'Y'])\n","          st.dataframe(df)\n","          st.write('ê²°ê³¼ëŠ” ì¸ê¸°ë„ìˆœìœ¼ë¡œ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.')\n","        except:\n","          st.write('ì•„ì‰½ê²Œë„ ' + user_location + ' ê·¼ì²˜ì—ëŠ” ' + cat1 + ' ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤ã… ã… ')\n"]}]},{"cell_type":"markdown","source":["# Streamlit Run"],"metadata":{"id":"CrQjfYxwN8KX"}},{"cell_type":"code","source":["!nohup streamlit run app2.py --server.port 80 &"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QzNZCMGBJxkQ","outputId":"8b2fd6e5-2520-40db-a629-c2093a617441","executionInfo":{"status":"ok","timestamp":1676039675395,"user_tz":-540,"elapsed":631,"user":{"displayName":"JIN","userId":"06208610298616237541"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["nohup: appending output to 'nohup.out'\n"]}]},{"cell_type":"markdown","source":["# ngrok connect&Take Page"],"metadata":{"id":"Qz34p3i1OA3R"}},{"cell_type":"code","source":["url = ngrok.connect(port='80')\n","url"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQ_LI3eNJ5Eo","outputId":"4ed266a4-e005-408b-abb7-6107b16011f2","executionInfo":{"status":"ok","timestamp":1676039688867,"user_tz":-540,"elapsed":1022,"user":{"displayName":"JIN","userId":"06208610298616237541"}}},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<NgrokTunnel: \"http://f90c-35-247-149-177.ngrok.io\" -> \"http://localhost:80\">"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["#  Killing Page"],"metadata":{"id":"3SSkgD37OHm3"}},{"cell_type":"code","source":["ngrok.kill()"],"metadata":{"id":"h9ZrUmTJKHhv"},"execution_count":null,"outputs":[]}]}