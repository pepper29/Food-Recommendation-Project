{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34813,
     "status": "ok",
     "timestamp": 1675651604523,
     "user": {
      "displayName": "JIN",
      "userId": "06208610298616237541"
     },
     "user_tz": -540
    },
    "id": "pBZuspXCaAKN",
    "outputId": "99b470c9-0a2f-4889-fa2a-7560f825bf84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\ADMIN\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-install-g1fbybsv\\\\numpy_80b572ac39e7439c9e2e94692585f7f3\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-install-g1fbybsv\\\\numpy_80b572ac39e7439c9e2e94692585f7f3\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-wheel-8m4f4jh_'\n",
      "       cwd: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-g1fbybsv\\numpy_80b572ac39e7439c9e2e94692585f7f3\\\n",
      "  Complete output (264 lines):\n",
      "  Running from numpy source directory.\n",
      "  C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-g1fbybsv\\numpy_80b572ac39e7439c9e2e94692585f7f3\\numpy\\distutils\\misc_util.py:476: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "    return is_string(s) and ('*' in s or '?' is s)\n",
      "  blas_opt_info:\n",
      "  blas_mkl_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries mkl_rt not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  blis_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries blis not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries openblas not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "  get_default_fcompiler: matching types: '['gnu', 'intelv', 'absoft', 'compaqv', 'intelev', 'gnu95', 'g95', 'intelvem', 'intelem', 'flang']'\n",
      "  customize GnuFCompiler\n",
      "  Could not locate executable g77\n",
      "  Could not locate executable f77\n",
      "  customize IntelVisualFCompiler\n",
      "  Could not locate executable ifort\n",
      "  Could not locate executable ifl\n",
      "  customize AbsoftFCompiler\n",
      "  Could not locate executable f90\n",
      "  customize CompaqVisualFCompiler\n",
      "  Could not locate executable DF\n",
      "  customize IntelItaniumVisualFCompiler\n",
      "  Could not locate executable efl\n",
      "  customize Gnu95FCompiler\n",
      "  Could not locate executable gfortran\n",
      "  Could not locate executable f95\n",
      "  customize G95FCompiler\n",
      "  Could not locate executable g95\n",
      "  customize IntelEM64VisualFCompiler\n",
      "  customize IntelEM64TFCompiler\n",
      "  Could not locate executable efort\n",
      "  Could not locate executable efc\n",
      "  customize PGroupFlangCompiler\n",
      "  Could not locate executable flang\n",
      "  don't know how to compile Fortran code on platform 'nt'\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_blas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_blas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_blas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_blas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  accelerate_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-g1fbybsv\\numpy_80b572ac39e7439c9e2e94692585f7f3\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Atlas (http://math-atlas.sourceforge.net/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [atlas]) or by setting\n",
      "      the ATLAS environment variable.\n",
      "    self.calc_info()\n",
      "  blas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries blas not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-g1fbybsv\\numpy_80b572ac39e7439c9e2e94692585f7f3\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Blas (http://www.netlib.org/blas/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [blas]) or by setting\n",
      "      the BLAS environment variable.\n",
      "    self.calc_info()\n",
      "  blas_src_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-g1fbybsv\\numpy_80b572ac39e7439c9e2e94692585f7f3\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Blas (http://www.netlib.org/blas/) sources not found.\n",
      "      Directories to search for the sources can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [blas_src]) or by setting\n",
      "      the BLAS_SRC environment variable.\n",
      "    self.calc_info()\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  'svnversion'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "  배치 파일이 아닙니다.\n",
      "  non-existing path in 'numpy\\\\distutils': 'site.cfg'\n",
      "  lapack_opt_info:\n",
      "  lapack_mkl_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries mkl_rt not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_lapack_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries openblas not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_clapack_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries openblas,lapack not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas,tatlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas,tatlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas,tatlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas,satlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas,satlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas,satlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  lapack_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-g1fbybsv\\numpy_80b572ac39e7439c9e2e94692585f7f3\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Lapack (http://www.netlib.org/lapack/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [lapack]) or by setting\n",
      "      the LAPACK environment variable.\n",
      "    self.calc_info()\n",
      "  lapack_src_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-g1fbybsv\\numpy_80b572ac39e7439c9e2e94692585f7f3\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Lapack (http://www.netlib.org/lapack/) sources not found.\n",
      "      Directories to search for the sources can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [lapack_src]) or by setting\n",
      "      the LAPACK_SRC environment variable.\n",
      "    self.calc_info()\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py:275: UserWarning: Unknown distribution option: 'define_macros'\n",
      "    warnings.warn(msg)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running config_cc\n",
      "  unifing config_cc, config, build_clib, build_ext, build commands --compiler options\n",
      "  running config_fc\n",
      "  unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options\n",
      "  running build_src\n",
      "  build_src\n",
      "  building py_modules sources\n",
      "  creating build\n",
      "  creating build\\src.win-amd64-3.9\n",
      "  creating build\\src.win-amd64-3.9\\numpy\n",
      "  creating build\\src.win-amd64-3.9\\numpy\\distutils\n",
      "  building library \"npymath\" sources\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for numpy\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\ADMIN\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-install-g1fbybsv\\\\numpy_80b572ac39e7439c9e2e94692585f7f3\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-install-g1fbybsv\\\\numpy_80b572ac39e7439c9e2e94692585f7f3\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' clean --all\n",
      "       cwd: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-g1fbybsv\\numpy_80b572ac39e7439c9e2e94692585f7f3\n",
      "  Complete output (10 lines):\n",
      "  Running from numpy source directory.\n",
      "  \n",
      "  `setup.py clean` is not supported, use one of the following instead:\n",
      "  \n",
      "    - `git clean -xdf` (cleans all files)\n",
      "    - `git clean -Xdf` (cleans all versioned files, doesn't touch\n",
      "                        files that aren't checked into the git repo)\n",
      "  \n",
      "  Add `--force` to your command to use it anyway if you must (unsupported).\n",
      "  \n",
      "  ----------------------------------------\n",
      "  ERROR: Failed cleaning build dir for numpy\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\ADMIN\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-install-g1fbybsv\\\\numpy_80b572ac39e7439c9e2e94692585f7f3\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-install-g1fbybsv\\\\numpy_80b572ac39e7439c9e2e94692585f7f3\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-record-bc84wepl\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\ADMIN\\anaconda3\\Include\\numpy'\n",
      "         cwd: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-g1fbybsv\\numpy_80b572ac39e7439c9e2e94692585f7f3\\\n",
      "    Complete output (269 lines):\n",
      "    Running from numpy source directory.\n",
      "    \n",
      "    Note: if you need reliable uninstall behavior, then install\n",
      "    with pip instead of using `setup.py install`:\n",
      "    \n",
      "      - `pip install .`       (from a git repo or downloaded source\n",
      "                               release)\n",
      "      - `pip install numpy`   (last NumPy release on PyPi)\n",
      "    \n",
      "    \n",
      "    blas_opt_info:\n",
      "    blas_mkl_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries mkl_rt not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    blis_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries blis not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    openblas_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries openblas not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "    get_default_fcompiler: matching types: '['gnu', 'intelv', 'absoft', 'compaqv', 'intelev', 'gnu95', 'g95', 'intelvem', 'intelem', 'flang']'\n",
      "    customize GnuFCompiler\n",
      "    Could not locate executable g77\n",
      "    Could not locate executable f77\n",
      "    customize IntelVisualFCompiler\n",
      "    Could not locate executable ifort\n",
      "    Could not locate executable ifl\n",
      "    customize AbsoftFCompiler\n",
      "    Could not locate executable f90\n",
      "    customize CompaqVisualFCompiler\n",
      "    Could not locate executable DF\n",
      "    customize IntelItaniumVisualFCompiler\n",
      "    Could not locate executable efl\n",
      "    customize Gnu95FCompiler\n",
      "    Could not locate executable gfortran\n",
      "    Could not locate executable f95\n",
      "    customize G95FCompiler\n",
      "    Could not locate executable g95\n",
      "    customize IntelEM64VisualFCompiler\n",
      "    customize IntelEM64TFCompiler\n",
      "    Could not locate executable efort\n",
      "    Could not locate executable efc\n",
      "    customize PGroupFlangCompiler\n",
      "    Could not locate executable flang\n",
      "    don't know how to compile Fortran code on platform 'nt'\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_3_10_blas_threads_info:\n",
      "    Setting PTATLAS=ATLAS\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries tatlas not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_3_10_blas_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries satlas not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_blas_threads_info:\n",
      "    Setting PTATLAS=ATLAS\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries ptf77blas,ptcblas,atlas not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_blas_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries f77blas,cblas,atlas not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    accelerate_info:\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-g1fbybsv\\numpy_80b572ac39e7439c9e2e94692585f7f3\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "        Atlas (http://math-atlas.sourceforge.net/) libraries not found.\n",
      "        Directories to search for the libraries can be specified in the\n",
      "        numpy/distutils/site.cfg file (section [atlas]) or by setting\n",
      "        the ATLAS environment variable.\n",
      "      self.calc_info()\n",
      "    blas_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries blas not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-g1fbybsv\\numpy_80b572ac39e7439c9e2e94692585f7f3\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "        Blas (http://www.netlib.org/blas/) libraries not found.\n",
      "        Directories to search for the libraries can be specified in the\n",
      "        numpy/distutils/site.cfg file (section [blas]) or by setting\n",
      "        the BLAS environment variable.\n",
      "      self.calc_info()\n",
      "    blas_src_info:\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-g1fbybsv\\numpy_80b572ac39e7439c9e2e94692585f7f3\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "        Blas (http://www.netlib.org/blas/) sources not found.\n",
      "        Directories to search for the sources can be specified in the\n",
      "        numpy/distutils/site.cfg file (section [blas_src]) or by setting\n",
      "        the BLAS_SRC environment variable.\n",
      "      self.calc_info()\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    'svnversion'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "    배치 파일이 아닙니다.\n",
      "    non-existing path in 'numpy\\\\distutils': 'site.cfg'\n",
      "    lapack_opt_info:\n",
      "    lapack_mkl_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries mkl_rt not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    openblas_lapack_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries openblas not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    openblas_clapack_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries openblas,lapack not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_3_10_threads_info:\n",
      "    Setting PTATLAS=ATLAS\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries tatlas,tatlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries lapack_atlas not found in C:\\\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries tatlas,tatlas not found in C:\\\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries tatlas,tatlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "    <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_3_10_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries satlas,satlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries lapack_atlas not found in C:\\\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries satlas,satlas not found in C:\\\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries satlas,satlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "    <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_threads_info:\n",
      "    Setting PTATLAS=ATLAS\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries ptf77blas,ptcblas,atlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries lapack_atlas not found in C:\\\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries ptf77blas,ptcblas,atlas not found in C:\\\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries ptf77blas,ptcblas,atlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "    <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries f77blas,cblas,atlas not found in C:\\Users\\ADMIN\\anaconda3\\lib\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries lapack_atlas not found in C:\\\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries f77blas,cblas,atlas not found in C:\\\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries lapack_atlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries f77blas,cblas,atlas not found in C:\\Users\\ADMIN\\anaconda3\\libs\n",
      "    <class 'numpy.distutils.system_info.atlas_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    lapack_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries lapack not found in ['C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\anaconda3\\\\libs']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-g1fbybsv\\numpy_80b572ac39e7439c9e2e94692585f7f3\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "        Lapack (http://www.netlib.org/lapack/) libraries not found.\n",
      "        Directories to search for the libraries can be specified in the\n",
      "        numpy/distutils/site.cfg file (section [lapack]) or by setting\n",
      "        the LAPACK environment variable.\n",
      "      self.calc_info()\n",
      "    lapack_src_info:\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-g1fbybsv\\numpy_80b572ac39e7439c9e2e94692585f7f3\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "        Lapack (http://www.netlib.org/lapack/) sources not found.\n",
      "        Directories to search for the sources can be specified in the\n",
      "        numpy/distutils/site.cfg file (section [lapack_src]) or by setting\n",
      "        the LAPACK_SRC environment variable.\n",
      "      self.calc_info()\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py:275: UserWarning: Unknown distribution option: 'define_macros'\n",
      "      warnings.warn(msg)\n",
      "    running install\n",
      "    C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "      warnings.warn(\n",
      "    running build\n",
      "    running config_cc\n",
      "    unifing config_cc, config, build_clib, build_ext, build commands --compiler options\n",
      "    running config_fc\n",
      "    unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options\n",
      "    running build_src\n",
      "    build_src\n",
      "    building py_modules sources\n",
      "    building library \"npymath\" sources\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\ADMIN\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-install-g1fbybsv\\\\numpy_80b572ac39e7439c9e2e94692585f7f3\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-install-g1fbybsv\\\\numpy_80b572ac39e7439c9e2e94692585f7f3\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-record-bc84wepl\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\ADMIN\\anaconda3\\Include\\numpy' Check the logs for full command output.\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading mxnet-1.7.0.post2-py2.py3-none-win_amd64.whl (33.1 MB)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting requests<2.19.0,>=2.18.4\n",
      "  Downloading requests-2.18.4-py2.py3-none-any.whl (88 kB)\n",
      "Collecting numpy<1.17.0,>=1.8.2\n",
      "  Downloading numpy-1.16.6.zip (5.1 MB)\n",
      "Collecting urllib3<1.23,>=1.21.1\n",
      "  Downloading urllib3-1.22-py2.py3-none-any.whl (132 kB)\n",
      "Collecting idna<2.7,>=2.5\n",
      "  Downloading idna-2.6-py2.py3-none-any.whl (56 kB)\n",
      "Collecting chardet<3.1.0,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2021.10.8)\n",
      "Building wheels for collected packages: numpy\n",
      "  Building wheel for numpy (setup.py): started\n",
      "  Building wheel for numpy (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for numpy\n",
      "Failed to build numpy\n",
      "Installing collected packages: urllib3, idna, chardet, requests, numpy, graphviz, mxnet\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.9\n",
      "    Uninstalling urllib3-1.26.9:\n",
      "      Successfully uninstalled urllib3-1.26.9\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.3\n",
      "    Uninstalling idna-3.3:\n",
      "      Successfully uninstalled idna-3.3\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.27.1\n",
      "    Uninstalling requests-2.27.1:\n",
      "      Successfully uninstalled requests-2.27.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "    Running setup.py install for numpy: started\n",
      "    Running setup.py install for numpy: finished with status 'error'\n",
      "  Rolling back uninstall of numpy\n",
      "  Moving to c:\\users\\admin\\anaconda3\\lib\\site-packages\\numpy-1.21.5.dist-info\\\n",
      "   from C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\~umpy-1.21.5.dist-info\n",
      "  Moving to c:\\users\\admin\\anaconda3\\lib\\site-packages\\numpy\\\n",
      "   from C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\~umpy\n",
      "  Moving to c:\\users\\admin\\anaconda3\\scripts\\f2py-script.py\n",
      "   from C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-uninstall-gec091y2\\f2py-script.py\n",
      "  Moving to c:\\users\\admin\\anaconda3\\scripts\\f2py.exe\n",
      "   from C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-uninstall-gec091y2\\f2py.exe\n",
      "Collecting gluonnlp"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\ADMIN\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-install-e3ztjcse\\\\gluonnlp_9783b3fb4e31424dbc61e2dccc5b0635\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-install-e3ztjcse\\\\gluonnlp_9783b3fb4e31424dbc61e2dccc5b0635\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-wheel-_4hir6_e'\n",
      "       cwd: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-e3ztjcse\\gluonnlp_9783b3fb4e31424dbc61e2dccc5b0635\\\n",
      "  Complete output (124 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.9\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\n",
      "  copying src\\gluonnlp\\base.py -> build\\lib.win-amd64-3.9\\gluonnlp\n",
      "  copying src\\gluonnlp\\_constants.py -> build\\lib.win-amd64-3.9\\gluonnlp\n",
      "  copying src\\gluonnlp\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\calibration\n",
      "  copying src\\gluonnlp\\calibration\\collector.py -> build\\lib.win-amd64-3.9\\gluonnlp\\calibration\n",
      "  copying src\\gluonnlp\\calibration\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\calibration\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\baidu_ernie_data.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\candidate_sampler.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\classification.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\conll.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\dataloader.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\dataset.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\datasetloader.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\glue.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\intent_slot.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\question_answering.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\registry.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\sampler.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\sentiment.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\stream.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\super_glue.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\transforms.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\translation.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\utils.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\word_embedding_evaluation.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\embedding\n",
      "  copying src\\gluonnlp\\embedding\\evaluation.py -> build\\lib.win-amd64-3.9\\gluonnlp\\embedding\n",
      "  copying src\\gluonnlp\\embedding\\token_embedding.py -> build\\lib.win-amd64-3.9\\gluonnlp\\embedding\n",
      "  copying src\\gluonnlp\\embedding\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\embedding\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\initializer\n",
      "  copying src\\gluonnlp\\initializer\\initializer.py -> build\\lib.win-amd64-3.9\\gluonnlp\\initializer\n",
      "  copying src\\gluonnlp\\initializer\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\initializer\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\activation_regularizer.py -> build\\lib.win-amd64-3.9\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\label_smoothing.py -> build\\lib.win-amd64-3.9\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\loss.py -> build\\lib.win-amd64-3.9\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\loss\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\metric\n",
      "  copying src\\gluonnlp\\metric\\length_normalized_loss.py -> build\\lib.win-amd64-3.9\\gluonnlp\\metric\n",
      "  copying src\\gluonnlp\\metric\\masked_accuracy.py -> build\\lib.win-amd64-3.9\\gluonnlp\\metric\n",
      "  copying src\\gluonnlp\\metric\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\metric\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\attention_cell.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\bert.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\bilm_encoder.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\block.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\convolutional_encoder.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\elmo.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\highway.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\info.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\language_model.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\lstmpcellwithclip.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\parameter.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\sampled_block.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\seq2seq_encoder_decoder.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\sequence_sampler.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\transformer.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\translation.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\utils.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\optimizer\n",
      "  copying src\\gluonnlp\\optimizer\\bert_adam.py -> build\\lib.win-amd64-3.9\\gluonnlp\\optimizer\n",
      "  copying src\\gluonnlp\\optimizer\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\optimizer\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\files.py -> build\\lib.win-amd64-3.9\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\parallel.py -> build\\lib.win-amd64-3.9\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\parameter.py -> build\\lib.win-amd64-3.9\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\seed.py -> build\\lib.win-amd64-3.9\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\version.py -> build\\lib.win-amd64-3.9\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\utils\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\bert.py -> build\\lib.win-amd64-3.9\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\elmo.py -> build\\lib.win-amd64-3.9\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\subwords.py -> build\\lib.win-amd64-3.9\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\vocab.py -> build\\lib.win-amd64-3.9\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\vocab\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\batchify.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\embedding.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\language_model.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\batchify\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\data\\bert\n",
      "  copying src\\gluonnlp\\data\\bert\\glue.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\bert\n",
      "  copying src\\gluonnlp\\data\\bert\\squad.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\bert\n",
      "  copying src\\gluonnlp\\data\\bert\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\bert\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\google_billion_word.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\large_text_compression_benchmark.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\wikitext.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\corpora\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\data\\xlnet\n",
      "  copying src\\gluonnlp\\data\\xlnet\\squad.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\xlnet\n",
      "  copying src\\gluonnlp\\data\\xlnet\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\xlnet\n",
      "  creating build\\lib.win-amd64-3.9\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\cache.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\embedding.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\language_model.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\\train\n",
      "  running egg_info\n",
      "  writing src\\gluonnlp.egg-info\\PKG-INFO\n",
      "  writing dependency_links to src\\gluonnlp.egg-info\\dependency_links.txt\n",
      "  writing requirements to src\\gluonnlp.egg-info\\requires.txt\n",
      "  writing top-level names to src\\gluonnlp.egg-info\\top_level.txt\n",
      "  reading manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching '*.py' under directory 'gluonnlp'\n",
      "  warning: no previously-included files matching '*' found under directory 'tests'\n",
      "  warning: no previously-included files matching '*' found under directory 'scripts'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "  copying src\\gluonnlp\\data\\fast_bert_tokenizer.c -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\fast_bert_tokenizer.pyx -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "  running build_ext\n",
      "  skipping 'src/gluonnlp/data\\fast_bert_tokenizer.c' Cython extension (up-to-date)\n",
      "  building 'gluonnlp.data.fast_bert_tokenizer' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for gluonnlp\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\ADMIN\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-install-e3ztjcse\\\\gluonnlp_9783b3fb4e31424dbc61e2dccc5b0635\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-install-e3ztjcse\\\\gluonnlp_9783b3fb4e31424dbc61e2dccc5b0635\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-record-_zj0pmoa\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\ADMIN\\anaconda3\\Include\\gluonnlp'\n",
      "         cwd: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-e3ztjcse\\gluonnlp_9783b3fb4e31424dbc61e2dccc5b0635\\\n",
      "    Complete output (126 lines):\n",
      "    running install\n",
      "    C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "      warnings.warn(\n",
      "    running build\n",
      "    running build_py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.9\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\n",
      "    copying src\\gluonnlp\\base.py -> build\\lib.win-amd64-3.9\\gluonnlp\n",
      "    copying src\\gluonnlp\\_constants.py -> build\\lib.win-amd64-3.9\\gluonnlp\n",
      "    copying src\\gluonnlp\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\calibration\n",
      "    copying src\\gluonnlp\\calibration\\collector.py -> build\\lib.win-amd64-3.9\\gluonnlp\\calibration\n",
      "    copying src\\gluonnlp\\calibration\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\calibration\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\baidu_ernie_data.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\candidate_sampler.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\classification.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\conll.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\dataloader.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\dataset.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\datasetloader.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\glue.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\intent_slot.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\question_answering.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\registry.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\sampler.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\sentiment.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\stream.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\super_glue.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\transforms.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\translation.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\utils.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\word_embedding_evaluation.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\embedding\n",
      "    copying src\\gluonnlp\\embedding\\evaluation.py -> build\\lib.win-amd64-3.9\\gluonnlp\\embedding\n",
      "    copying src\\gluonnlp\\embedding\\token_embedding.py -> build\\lib.win-amd64-3.9\\gluonnlp\\embedding\n",
      "    copying src\\gluonnlp\\embedding\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\embedding\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\initializer\n",
      "    copying src\\gluonnlp\\initializer\\initializer.py -> build\\lib.win-amd64-3.9\\gluonnlp\\initializer\n",
      "    copying src\\gluonnlp\\initializer\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\initializer\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\activation_regularizer.py -> build\\lib.win-amd64-3.9\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\label_smoothing.py -> build\\lib.win-amd64-3.9\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\loss.py -> build\\lib.win-amd64-3.9\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\loss\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\metric\n",
      "    copying src\\gluonnlp\\metric\\length_normalized_loss.py -> build\\lib.win-amd64-3.9\\gluonnlp\\metric\n",
      "    copying src\\gluonnlp\\metric\\masked_accuracy.py -> build\\lib.win-amd64-3.9\\gluonnlp\\metric\n",
      "    copying src\\gluonnlp\\metric\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\metric\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\attention_cell.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\bert.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\bilm_encoder.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\block.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\convolutional_encoder.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\elmo.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\highway.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\info.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\language_model.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\lstmpcellwithclip.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\parameter.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\sampled_block.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\seq2seq_encoder_decoder.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\sequence_sampler.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\transformer.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\translation.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\utils.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\optimizer\n",
      "    copying src\\gluonnlp\\optimizer\\bert_adam.py -> build\\lib.win-amd64-3.9\\gluonnlp\\optimizer\n",
      "    copying src\\gluonnlp\\optimizer\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\optimizer\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\files.py -> build\\lib.win-amd64-3.9\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\parallel.py -> build\\lib.win-amd64-3.9\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\parameter.py -> build\\lib.win-amd64-3.9\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\seed.py -> build\\lib.win-amd64-3.9\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\version.py -> build\\lib.win-amd64-3.9\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\utils\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\bert.py -> build\\lib.win-amd64-3.9\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\elmo.py -> build\\lib.win-amd64-3.9\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\subwords.py -> build\\lib.win-amd64-3.9\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\vocab.py -> build\\lib.win-amd64-3.9\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\vocab\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\batchify.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\embedding.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\language_model.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\batchify\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\data\\bert\n",
      "    copying src\\gluonnlp\\data\\bert\\glue.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\bert\n",
      "    copying src\\gluonnlp\\data\\bert\\squad.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\bert\n",
      "    copying src\\gluonnlp\\data\\bert\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\bert\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\google_billion_word.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\large_text_compression_benchmark.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\wikitext.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\corpora\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\data\\xlnet\n",
      "    copying src\\gluonnlp\\data\\xlnet\\squad.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\xlnet\n",
      "    copying src\\gluonnlp\\data\\xlnet\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\data\\xlnet\n",
      "    creating build\\lib.win-amd64-3.9\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\cache.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\embedding.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\language_model.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\__init__.py -> build\\lib.win-amd64-3.9\\gluonnlp\\model\\train\n",
      "    running egg_info\n",
      "    writing src\\gluonnlp.egg-info\\PKG-INFO\n",
      "    writing dependency_links to src\\gluonnlp.egg-info\\dependency_links.txt\n",
      "    writing requirements to src\\gluonnlp.egg-info\\requires.txt\n",
      "    writing top-level names to src\\gluonnlp.egg-info\\top_level.txt\n",
      "    reading manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "    reading manifest template 'MANIFEST.in'\n",
      "    warning: no files found matching '*.py' under directory 'gluonnlp'\n",
      "    warning: no previously-included files matching '*' found under directory 'tests'\n",
      "    warning: no previously-included files matching '*' found under directory 'scripts'\n",
      "    adding license file 'LICENSE'\n",
      "    writing manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "    copying src\\gluonnlp\\data\\fast_bert_tokenizer.c -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\fast_bert_tokenizer.pyx -> build\\lib.win-amd64-3.9\\gluonnlp\\data\n",
      "    running build_ext\n",
      "    skipping 'src/gluonnlp/data\\fast_bert_tokenizer.c' Cython extension (up-to-date)\n",
      "    building 'gluonnlp.data.fast_bert_tokenizer' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\ADMIN\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-install-e3ztjcse\\\\gluonnlp_9783b3fb4e31424dbc61e2dccc5b0635\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-install-e3ztjcse\\\\gluonnlp_9783b3fb4e31424dbc61e2dccc5b0635\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-record-_zj0pmoa\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\ADMIN\\anaconda3\\Include\\gluonnlp' Check the logs for full command output.\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from gluonnlp) (1.21.5)\n",
      "Requirement already satisfied: cython in c:\\users\\admin\\anaconda3\\lib\\site-packages (from gluonnlp) (0.29.28)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\lib\\site-packages (from gluonnlp) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from packaging->gluonnlp) (3.0.4)\n",
      "Building wheels for collected packages: gluonnlp\n",
      "  Building wheel for gluonnlp (setup.py): started\n",
      "  Building wheel for gluonnlp (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for gluonnlp\n",
      "Failed to build gluonnlp\n",
      "Installing collected packages: gluonnlp\n",
      "    Running setup.py install for gluonnlp: started\n",
      "    Running setup.py install for gluonnlp: finished with status 'error'\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==3.0.2\n",
      "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (2022.3.15)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (21.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (0.1.97)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (1.21.5)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (2.18.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (3.6.0)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "  Downloading tokenizers-0.8.1rc1.tar.gz (97 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==3.0.2) (0.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from packaging->transformers==3.0.2) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.2) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.2) (2021.10.8)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.2) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.2) (3.0.4)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sacremoses->transformers==3.0.2) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sacremoses->transformers==3.0.2) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n",
      "Building wheels for collected packages: tokenizers, sacremoses\n",
      "  Building wheel for tokenizers (PEP 517): started\n",
      "  Building wheel for tokenizers (PEP 517): finished with status 'error'\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=fb585e3d0afc78c9230cfc24b22329bd97bc986f56f7e010fbd42c786063fe61\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\12\\1c\\3d\\46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
      "Successfully built sacremoses\n",
      "Failed to build tokenizers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\ADMIN\\anaconda3\\python.exe' 'C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' build_wheel 'C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmpai_6fsuv'\n",
      "       cwd: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-install-714zhe98\\tokenizers_e949bde5735d44e6b402a11909c1e49b\n",
      "  Complete output (48 lines):\n",
      "  C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-build-env-aygwhwe5\\overlay\\Lib\\site-packages\\setuptools\\dist.py:534: UserWarning: Normalizing '0.8.1.rc1' to '0.8.1rc1'\n",
      "    warnings.warn(tmpl.format(**locals()))\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\n",
      "  copying tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\\models\n",
      "  copying tokenizers\\models\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\models\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\\decoders\n",
      "  copying tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\decoders\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\\normalizers\n",
      "  copying tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\normalizers\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\\pre_tokenizers\n",
      "  copying tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\pre_tokenizers\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\\processors\n",
      "  copying tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\processors\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\\trainers\n",
      "  copying tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\trainers\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\tokenizers\n",
      "  copying tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\tokenizers\\models\n",
      "  copying tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\tokenizers\\decoders\n",
      "  copying tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\tokenizers\\normalizers\n",
      "  copying tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\tokenizers\\pre_tokenizers\n",
      "  copying tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\tokenizers\\processors\n",
      "  copying tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\tokenizers\\trainers\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for tokenizers\n",
      "ERROR: Could not build wheels for tokenizers which use PEP 517 and cannot be installed directly\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp39-cp39-win_amd64.whl (162.5 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (4.1.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet\n",
    "!pip install gluonnlp pandas tqdm\n",
    "!pip install sentencepiece\n",
    "!pip install transformers==3.0.2\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIB_XYX-aC1n",
    "outputId": "28f63e0c-735a-4d6f-ea5c-4a27eb600c44"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (859343003.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [6]\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#깃허브에서 KoBERT 파일 로드\n",
    "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "m9E34IEfaC3u"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gluonnlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgluonnlp\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnlp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm, tqdm_notebook\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gluonnlp'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMLUZTIaaC5p"
   },
   "outputs": [],
   "source": [
    "#kobert\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "#transformers\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhzXXMQaaC7w"
   },
   "outputs": [],
   "source": [
    "#GPU 사용\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcCPo0KNaQ_I"
   },
   "outputs": [],
   "source": [
    "#BERT 모델, Vocabulary 불러오기\n",
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jj3RiTq4aRBO"
   },
   "outputs": [],
   "source": [
    "#구글드라이브 연동\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cYx4BUiGaRDQ"
   },
   "outputs": [],
   "source": [
    "#데이터불러오기\n",
    "import pandas as pd\n",
    "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/refer_data/크롤링이후/clean_total_crawling10.2(1500개씩뽑은데이터).csv', encoding='utf8')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDgeD0TKaRFE"
   },
   "outputs": [],
   "source": [
    "#예시로 10개 뽑아보기\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HueC6PnUaRG_"
   },
   "outputs": [],
   "source": [
    "data.loc[(data['keyword_kor'] == \"곱창\"), 'keyword_kor'] = 1\n",
    "data.loc[(data['keyword_kor'] == \"국수\"), 'keyword_kor'] = 2\n",
    "data.loc[(data['keyword_kor'] == \"돈카츠\"), 'keyword_kor'] = 3\n",
    "data.loc[(data['keyword_kor'] == \"디저트\"), 'keyword_kor'] = 4\n",
    "data.loc[(data['keyword_kor'] == \"라멘\"), 'keyword_kor'] = 5\n",
    "data.loc[(data['keyword_kor'] == \"버거\"), 'keyword_kor'] = 6\n",
    "data.loc[(data['keyword_kor'] == \"베이커리\"), 'keyword_kor'] = 7\n",
    "data.loc[(data['keyword_kor'] == \"분식\"), 'keyword_kor'] = 8\n",
    "data.loc[(data['keyword_kor'] == \"스시\"), 'keyword_kor'] = 9\n",
    "data.loc[(data['keyword_kor'] == \"아시아음식\"), 'keyword_kor'] = 10\n",
    "data.loc[(data['keyword_kor'] == \"양식\"), 'keyword_kor'] = 11\n",
    "data.loc[(data['keyword_kor'] == \"전골\"), 'keyword_kor'] = 12\n",
    "data.loc[(data['keyword_kor'] == \"중식\"), 'keyword_kor'] = 13\n",
    "data.loc[(data['keyword_kor'] == \"치킨\"), 'keyword_kor'] = 14\n",
    "data.loc[(data['keyword_kor'] == \"타코\"), 'keyword_kor'] = 15\n",
    "data.loc[(data['keyword_kor'] == \"한식\"), 'keyword_kor'] = 16\n",
    "data.loc[(data['keyword_kor'] == \"해산물\"), 'keyword_kor'] = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RQyGCh0aRJJ"
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for q, label in zip(data['reviews'], data['keyword_kor'])  :\n",
    "    data = []\n",
    "    data.append(q)\n",
    "    data.append(str(label))\n",
    "\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RawiQsUodTgQ"
   },
   "outputs": [],
   "source": [
    "print(data_list[0])\n",
    "print(data_list[6000])\n",
    "print(data_list[12000])\n",
    "print(data_list[18000])\n",
    "print(data_list[24000])\n",
    "print(data_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CRmJ_MMKdTiO"
   },
   "outputs": [],
   "source": [
    "# Output\n",
    "'''\n",
    "['냄새안나고 맛있어요', '1']\n",
    "['미슐랭이라구 해서 기대했는데 면이 너무 많아서인지 금방 물렸다 사이드로 주문한 에비마요가 전맛탱', '5']\n",
    "['조용한 가게 분위기나 직원분들에게서 전해지는 느낌이 좋아서 기분좋게 식사했습니다 샤리양이 적어서 그랬는지 배부르다고 느끼진 않았습니다', '9']\n",
    "['어랏 처음엔 그냥 먹었는데 날이 갈수록 맛있어지는 맛집인가보네요 적당히 맵고 새콤 달콤한 오이무침 짱 다른 메뉴들도 슬슬 궁금해지네요 딤섬도 그럭저럭 좋았구요 저랑 간이 잘 맞는 식당이에요', '13']\n",
    "['서비스최악 기다리는데 안내도 없고 호일위에 음식만 덩그러니 올려놓고 말도 없이감 분위기도 별로 팔에 문신그려진 아저씨들 옴 맛은 왜 특별한지 모르겠는 상상가는 맛 다신안감', '17']\n",
    "['오포리 근처 숯불구이 장어 전문점인데 장어가 진짜 크고 실하다 숯불에 구워 고소하고 부드러운데 느끼함은 쏙 빠진 장어가 진짜 맛있다 찬은 상당히 간단하고 거의 장어에만 집중하는 곳 아주머니가 잘 구워주시고 둘이 키로에 그람 추가하니 배 부르다 성인 둘이면 일키로만 먹어도 되지만 맛있어서 과식 숯불구이 장어집 중에선 아마도 여기가 가장 낫지 않을까 싶음', '17']\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NexpYd_es_d"
   },
   "outputs": [],
   "source": [
    "#train & test 데이터로 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "                                                         \n",
    "dataset_train, dataset_test = train_test_split(data_list, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WobUXzvAdTkU"
   },
   "outputs": [],
   "source": [
    "print(len(dataset_train))\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejf0cvetdTl_"
   },
   "outputs": [],
   "source": [
    "# BERT 모델에 들어가기 위한 dataset을 만들어주는 클래스\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAbXUDGSdToA"
   },
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "#위 코드는 BERT 모델의 토큰화 및 학습에 사용할 파라미터로, 숫자를 조정해도 된다.\n",
    "# 이번 프로젝트에서는 batch_size를 64, epochs수를 10으로 설정하였다.\n",
    "\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 3\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1675645927638,
     "user": {
      "displayName": "JIN",
      "userId": "06208610298616237541"
     },
     "user_tz": -540
    },
    "id": "UBYvXl7_dTr2",
    "outputId": "f5c2eab4-bec8-46f7-d4fd-b08c20540368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 7900,
     "status": "ok",
     "timestamp": 1675645937684,
     "user": {
      "displayName": "JIN",
      "userId": "06208610298616237541"
     },
     "user_tz": -540
    },
    "id": "acOpXHxodTt-"
   },
   "outputs": [],
   "source": [
    "# 한편 토큰화 & 패딩을 거치면 데이터는 다음과 같은 형식을 갖게 된다.\n",
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675645937685,
     "user": {
      "displayName": "JIN",
      "userId": "06208610298616237541"
     },
     "user_tz": -540
    },
    "id": "kg48PLNVdTv5",
    "outputId": "d65cd8d8-bb2c-4842-8db9-727f2cdbb997"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2, 1875, 6193, 4207, 7795, 4384, 7096,  517, 5330, 5591, 7018,\n",
       "        6553, 3924, 2269, 6999, 2623, 5778, 4354, 4955, 5415, 5354, 7096,\n",
       "        4626, 7217, 7782, 6705, 5439, 1875, 6193, 6896, 1682, 3372, 7096,\n",
       "         745, 7828, 1022, 6957, 6999, 4299, 5859, 1458, 1967, 7141, 7330,\n",
       "        3192, 5330, 1698, 1267, 5889, 4128, 5330, 3094, 5439, 3198, 7794,\n",
       "        1967, 7354, 7139,    3,    1,    1,    1,    1,    1], dtype=int32),\n",
       " array(59, dtype=int32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       dtype=int32),\n",
       " 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1675645937685,
     "user": {
      "displayName": "JIN",
      "userId": "06208610298616237541"
     },
     "user_tz": -540
    },
    "id": "pspRQsNbdTyB",
    "outputId": "4940af5c-92db-487b-9e19-ccf5c57e3027"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# 아래 코드를 실행하여 torch 형식의 dataset을 만들어준다\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQWzB2otdT0I"
   },
   "outputs": [],
   "source": [
    "# KoBERT 학습모델 만들기\n",
    "# 학습시킬 KoBERT 모델을 만들어야 하는데, 아래 코드에서 다중분류할 클래스 수 만큼 num_classes 변수를 수정해주어야 한다. 이번 프로젝트에서는 7가지의 class를 분류하기 때문에 7로 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1675645937685,
     "user": {
      "displayName": "JIN",
      "userId": "06208610298616237541"
     },
     "user_tz": -540
    },
    "id": "E4_iqfPNdT15"
   },
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=18,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1675645942775,
     "user": {
      "displayName": "JIN",
      "userId": "06208610298616237541"
     },
     "user_tz": -540
    },
    "id": "oMrC1fyddT4B"
   },
   "outputs": [],
   "source": [
    "model = BERTClassifier(bertmodel,  dr_rate=0.5) #.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1675646125893,
     "user": {
      "displayName": "JIN",
      "userId": "06208610298616237541"
     },
     "user_tz": -540
    },
    "id": "mUBwFV2LdT5l"
   },
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1675646127270,
     "user": {
      "displayName": "JIN",
      "userId": "06208610298616237541"
     },
     "user_tz": -540
    },
    "id": "sEbbz0EEfS35"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1675646178873,
     "user": {
      "displayName": "JIN",
      "userId": "06208610298616237541"
     },
     "user_tz": -540
    },
    "id": "UHkHiZhlfS5n"
   },
   "outputs": [],
   "source": [
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1675646180487,
     "user": {
      "displayName": "JIN",
      "userId": "06208610298616237541"
     },
     "user_tz": -540
    },
    "id": "y0urQgQSfS7l"
   },
   "outputs": [],
   "source": [
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1675646182376,
     "user": {
      "displayName": "JIN",
      "userId": "06208610298616237541"
     },
     "user_tz": -540
    },
    "id": "PzFBSQ_JfS9i"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1675646183105,
     "user": {
      "displayName": "JIN",
      "userId": "06208610298616237541"
     },
     "user_tz": -540
    },
    "id": "zgHoYAaDfS_b",
    "outputId": "30c214f1-4f2e-48b4-970e-18c5b3f89ff4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f39f5c6cdf0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0OPFtENfTBA"
   },
   "outputs": [],
   "source": [
    " # KoBERT 모델 학습시키기\n",
    "  # 학습 데이터셋과 학습 모델 준비가 다 끝났다면 이제 아래 코드 실행을 통해 KoBERT 모델을 학습시켜준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "executionInfo": {
     "elapsed": 722,
     "status": "error",
     "timestamp": 1675651521261,
     "user": {
      "displayName": "JIN",
      "userId": "06208610298616237541"
     },
     "user_tz": -540
    },
    "id": "WWpR8R81fTC_",
    "outputId": "2d191cfb-1937-47a9-8bc9-e1eee6113887"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1d65527f62b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long() #.to(device)\n",
    "        segment_ids = segment_ids.long() #.to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long() #.to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long() #.to(device)\n",
    "        segment_ids = segment_ids.long() #.to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long() #.to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mdHmAR9kiw2"
   },
   "outputs": [],
   "source": [
    "# 새로운 문장 테스트\n",
    "# 마지막 단계로, 앞에서 훈련시킨 KoBERT 모델에 새로운 문장을 넣어, 감정 분류를 잘 하는지 테스트 해보려고 한다.\n",
    "\n",
    "# 새로운 문장 역시 토크화 과정을 시켜줌\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "td9llWrifTEs"
   },
   "outputs": [],
   "source": [
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-xCc631fTGf"
   },
   "outputs": [],
   "source": [
    "# 예측을 해주기 위한 predict 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ACKGNqIfTIN"
   },
   "outputs": [],
   "source": [
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model1.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model1(token_ids, valid_length, segment_ids)\n",
    "\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "\n",
    "            if np.argmax(logits) == 1:\n",
    "                test_eval.append(\"곱창\")\n",
    "            elif np.argmax(logits) == 2:\n",
    "                test_eval.append(\"국수\")\n",
    "            elif np.argmax(logits) == 3:\n",
    "                test_eval.append(\"돈카츠\")\n",
    "            elif np.argmax(logits) == 4:\n",
    "                test_eval.append(\"디저트\")\n",
    "            elif np.argmax(logits) == 5:\n",
    "                test_eval.append(\"라멘\")\n",
    "            elif np.argmax(logits) == 6:\n",
    "                test_eval.append(\"버거\")\n",
    "            elif np.argmax(logits) == 7:\n",
    "                test_eval.append(\"베이커리\")\n",
    "            elif np.argmax(logits) == 8:\n",
    "                test_eval.append(\"분식\")\n",
    "            elif np.argmax(logits) == 9:\n",
    "                test_eval.append(\"스시\")\n",
    "            elif np.argmax(logits) == 10:\n",
    "                test_eval.append(\"아시아음식\")\n",
    "            elif np.argmax(logits) == 11:\n",
    "                test_eval.append(\"양식\")\n",
    "            elif np.argmax(logits) == 12:\n",
    "                test_eval.append(\"전골\")\n",
    "            elif np.argmax(logits) == 13:\n",
    "                test_eval.append(\"중식\")\n",
    "            elif np.argmax(logits) == 14:\n",
    "                test_eval.append(\"치킨\")\n",
    "            elif np.argmax(logits) == 15:\n",
    "                test_eval.append(\"타코\")\n",
    "            elif np.argmax(logits) == 16:\n",
    "                test_eval.append(\"한식\")\n",
    "            elif np.argmax(logits) == 17:\n",
    "                test_eval.append(\"해산물\")\n",
    "\n",
    "        print(\">> 입력하신 내용을 종합해 분석결과, \" + test_eval[0] + \"이(가) 가장 적합하다고 생각됩니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PPWJd7bfTKE"
   },
   "outputs": [],
   "source": [
    "#질문 무한반복하기! 0 입력시 종료\n",
    "end = 1\n",
    "while end == 1 :\n",
    "    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n",
    "    if sentence == 0 :\n",
    "        break\n",
    "    predict(sentence)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCHUJUuNfTL6"
   },
   "outputs": [],
   "source": [
    "#모델저장\n",
    "# 파이토치사용시\n",
    "from transformers import BertForMaskedLM #파이토치\n",
    "torch_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 모델 클래스 이름.from_pretrained(저장된 디렉토리) 형태\n",
    "torch_model.save_pretrained('/content/drive/MyDrive/Colab Notebooks/Save_data/model1.pt') # 파이토치 기반 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABiEJHdGfTN2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTREfYFcfTPp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKvK-hLsfTRY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ouaaJfkXfTTJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJM937NmfTU6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDsDKykNfTWo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPVo80EAuYvKF3Ny5ISFZbx",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
