{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"pBZuspXCaAKN"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mxnet\n","  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting graphviz\u003c0.9.0,\u003e=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests\u003c3,\u003e=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet) (2.25.1)\n","Requirement already satisfied: numpy\u003c2.0.0,\u003e1.16.0 in /usr/local/lib/python3.8/dist-packages (from mxnet) (1.21.6)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.8/dist-packages (from requests\u003c3,\u003e=2.20.0-\u003emxnet) (2.10)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests\u003c3,\u003e=2.20.0-\u003emxnet) (1.24.3)\n","Requirement already satisfied: chardet\u003c5,\u003e=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests\u003c3,\u003e=2.20.0-\u003emxnet) (4.0.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests\u003c3,\u003e=2.20.0-\u003emxnet) (2022.12.7)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.9.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.5/344.5 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n","Requirement already satisfied: numpy\u003e=1.16.0 in /usr/local/lib/python3.8/dist-packages (from gluonnlp) (1.21.6)\n","Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from gluonnlp) (0.29.33)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from gluonnlp) (23.0)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil\u003e=2.7.3-\u003epandas) (1.15.0)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp38-cp38-linux_x86_64.whl size=689003 sha256=f778888b0c5b79291133c151d5545e321606b4173fc4aaf80770ce2fbae42245\n","  Stored in directory: /root/.cache/pip/wheels/b6/93/9d/2237550c409eb3ed725d6302b7897ddd9a037b40cef66dcd9c\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub\u003c1.0,\u003e=0.11.0\n","  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,\u003c0.14,\u003e=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.11.0-\u003etransformers) (4.4.0)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (2022.12.7)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: chardet\u003c5,\u003e=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (4.0.0)\n"]}],"source":["!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers\n","!pip install torch\n","\n","# !pip install gluonnlp pandas tqdm   \n","# !pip install mxnet\n","# !pip install sentencepiece==0.1.91\n","# !pip install transformers==4.8.2\n","# !pip install torch ==1.8.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xIB_XYX-aC1n"},"outputs":[],"source":["#깃허브에서 KoBERT 파일 로드\n","!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m9E34IEfaC3u"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CMLUZTIaaC5p"},"outputs":[],"source":["#kobert\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","\n","#transformers\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","from transformers import BertModel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JhzXXMQaaC7w"},"outputs":[],"source":["#GPU 사용\n","# device = torch.device(\"cuda:0\")\n","device = torch.device(\"cuda:1\")\n","# device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8012,"status":"ok","timestamp":1675756768758,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"HOEmI_1E16rm","outputId":"b21b2203-73c1-4c7d-c940-e69ba79e92b8"},"outputs":[{"data":{"text/plain":["tensor([0.6030, 0.5053, 0.8142, 0.0739, 0.6487, 0.1462, 0.1513, 0.7166, 0.9973,\n","        0.6465], device='cuda:0')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# torch.cuda.is_available()\n","# torch.rand(10).cuda()\n","# # export TORCH_CUDA_ARCH_LIST=6.1\n","# import torch\n","# import torch.nn as nn\n","# import torchvision.datasets as dsets\n","\n","# use_cuda = True\n","# if use_cuda and torch.cuda.is_available():\n","#     net.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14216,"status":"ok","timestamp":1675822797754,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"TcCPo0KNaQ_I","outputId":"82cc68ef-41ce-4f32-8051-d14bdd080188"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n","/content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"]}],"source":["#BERT 모델, Vocabulary 불러오기\n","bertmodel, vocab = get_pytorch_kobert_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16092,"status":"ok","timestamp":1675822813842,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"Jj3RiTq4aRBO","outputId":"6c4c9761-96a2-4f1b-a4cc-6ef692bdb6b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["#구글드라이브 연동\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1653,"status":"ok","timestamp":1675823436889,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"cYx4BUiGaRDQ","outputId":"4416a7d9-02f4-4674-8829-a245902d7978"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'pandas.core.frame.DataFrame'\u003e\n","RangeIndex: 24785 entries, 0 to 24784\n","Data columns (total 4 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   index_num    24785 non-null  int64 \n"," 1   reviews      24785 non-null  object\n"," 2   keyword_kor  24785 non-null  object\n"," 3   keyword_num  24785 non-null  int64 \n","dtypes: int64(2), object(2)\n","memory usage: 774.7+ KB\n"]}],"source":["#데이터불러오기\n","import pandas as pd\n","data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/refer_data/크롤링이후/clean_total_crawling10.2(1500개씩뽑은데이터).csv', encoding='utf8')\n","data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1675823436889,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"tDgeD0TKaRFE","outputId":"f265f6fd-bdc4-4a3b-8d5d-2ce45e2b9887"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-76a313c5-2ed8-4da3-8b2b-2b2269eb8591\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eindex_num\u003c/th\u003e\n","      \u003cth\u003ereviews\u003c/th\u003e\n","      \u003cth\u003ekeyword_kor\u003c/th\u003e\n","      \u003cth\u003ekeyword_num\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e냄새안나고 맛있어요\u003c/td\u003e\n","      \u003ctd\u003e곱창\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e부추된장찌개랑 양밥\u003c/td\u003e\n","      \u003ctd\u003e곱창\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e곱창과 전골을 추천\u003c/td\u003e\n","      \u003ctd\u003e곱창\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e생각만큼은 아니었다\u003c/td\u003e\n","      \u003ctd\u003e곱창\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e망원 청어람 볶음밥\u003c/td\u003e\n","      \u003ctd\u003e곱창\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e5\u003c/th\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e가성비 최고 곱창집\u003c/td\u003e\n","      \u003ctd\u003e곱창\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e6\u003c/th\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e맛있지만 가격이 셈\u003c/td\u003e\n","      \u003ctd\u003e곱창\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e7\u003c/th\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e특양구이 대창 갈비\u003c/td\u003e\n","      \u003ctd\u003e곱창\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e8\u003c/th\u003e\n","      \u003ctd\u003e8\u003c/td\u003e\n","      \u003ctd\u003e소곱창구이 황소막창\u003c/td\u003e\n","      \u003ctd\u003e곱창\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e9\u003c/th\u003e\n","      \u003ctd\u003e9\u003c/td\u003e\n","      \u003ctd\u003e곱을 느낄 수 있음\u003c/td\u003e\n","      \u003ctd\u003e곱창\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76a313c5-2ed8-4da3-8b2b-2b2269eb8591')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-76a313c5-2ed8-4da3-8b2b-2b2269eb8591 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-76a313c5-2ed8-4da3-8b2b-2b2269eb8591');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["   index_num     reviews keyword_kor  keyword_num\n","0          0  냄새안나고 맛있어요          곱창            1\n","1          1  부추된장찌개랑 양밥          곱창            1\n","2          2  곱창과 전골을 추천          곱창            1\n","3          3  생각만큼은 아니었다          곱창            1\n","4          4  망원 청어람 볶음밥          곱창            1\n","5          5  가성비 최고 곱창집          곱창            1\n","6          6  맛있지만 가격이 셈          곱창            1\n","7          7  특양구이 대창 갈비          곱창            1\n","8          8  소곱창구이 황소막창          곱창            1\n","9          9  곱을 느낄 수 있음          곱창            1"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["#예시로 10개 뽑아보기\n","data.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1675823437342,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"qdq0VOmDX35v","outputId":"52e5181a-b0f1-41de-fb6e-9f17d57a7d72"},"outputs":[{"data":{"text/plain":["곱창       1500\n","아시아음식    1500\n","한식       1500\n","타코       1500\n","중식       1500\n","전골       1500\n","양식       1500\n","스시       1500\n","분식       1500\n","베이커리     1500\n","버거       1500\n","라멘       1500\n","디저트      1500\n","해산물      1500\n","국수       1474\n","치킨       1254\n","돈카츠      1057\n","Name: keyword_kor, dtype: int64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# sns을 이용한 데이터 시각화\n","import seaborn as sns\n","data['keyword_kor'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":653,"status":"ok","timestamp":1675823440167,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"6Lk_pgYGYJXj","outputId":"952d4d4b-4372-4d21-fcb0-afca39730f73"},"outputs":[{"data":{"text/plain":["\u003cmatplotlib.axes._subplots.AxesSubplot at 0x7f537c984760\u003e"]},"execution_count":15,"metadata":{},"output_type":"execute_result"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44273 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52285 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44397 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49688 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46024 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52852 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52768 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46356 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51200 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 53944 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46972 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47704 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48260 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44144 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48288 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51060 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52964 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47532 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48516 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49885 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49828 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49884 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50500 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51020 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50577 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51204 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44264 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51473 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52824 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 53416 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 53440 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 53076 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54620 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54644 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49328 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47932 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44273 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52285 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44397 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49688 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46024 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52852 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52768 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46356 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51200 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 53944 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46972 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47704 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48260 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44144 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48288 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51060 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52964 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47532 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48516 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49885 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49828 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49884 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50500 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51020 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50577 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51204 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44264 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51473 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52824 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 53416 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 53440 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 53076 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54620 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54644 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49328 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47932 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"]},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# 각 클래스별 데이터분포 확인\n","sns.countplot(data=data, x='keyword_kor')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HueC6PnUaRG_"},"outputs":[],"source":["# 총 17개의 카테고리를 만들어줌\n","data.loc[(data['keyword_kor'] == \"곱창\"), 'keyword_kor'] = 1\n","data.loc[(data['keyword_kor'] == \"국수\"), 'keyword_kor'] = 2\n","data.loc[(data['keyword_kor'] == \"돈카츠\"), 'keyword_kor'] = 3\n","data.loc[(data['keyword_kor'] == \"디저트\"), 'keyword_kor'] = 4\n","data.loc[(data['keyword_kor'] == \"라멘\"), 'keyword_kor'] = 5\n","data.loc[(data['keyword_kor'] == \"버거\"), 'keyword_kor'] = 6\n","data.loc[(data['keyword_kor'] == \"베이커리\"), 'keyword_kor'] = 7\n","data.loc[(data['keyword_kor'] == \"분식\"), 'keyword_kor'] = 8\n","data.loc[(data['keyword_kor'] == \"스시\"), 'keyword_kor'] = 9\n","data.loc[(data['keyword_kor'] == \"아시아음식\"), 'keyword_kor'] = 10\n","data.loc[(data['keyword_kor'] == \"양식\"), 'keyword_kor'] = 11\n","data.loc[(data['keyword_kor'] == \"전골\"), 'keyword_kor'] = 12\n","data.loc[(data['keyword_kor'] == \"중식\"), 'keyword_kor'] = 13\n","data.loc[(data['keyword_kor'] == \"치킨\"), 'keyword_kor'] = 14\n","data.loc[(data['keyword_kor'] == \"타코\"), 'keyword_kor'] = 15\n","data.loc[(data['keyword_kor'] == \"한식\"), 'keyword_kor'] = 16\n","data.loc[(data['keyword_kor'] == \"해산물\"), 'keyword_kor'] = 17"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7RQyGCh0aRJJ"},"outputs":[],"source":["data_list = []\n","for q, label in zip(data['reviews'], data['keyword_kor'])  :\n","    data = []\n","    data.append(q)\n","    data.append(str(label))\n","\n","    data_list.append(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1675823443613,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"RawiQsUodTgQ","outputId":"cd812610-5af3-44b7-8b83-c974cbfb7396"},"outputs":[{"name":"stdout","output_type":"stream","text":["['냄새안나고 맛있어요', '1']\n","['미슐랭이라구 해서 기대했는데 면이 너무 많아서인지 금방 물렸다 사이드로 주문한 에비마요가 전맛탱', '5']\n","['조용한 가게 분위기나 직원분들에게서 전해지는 느낌이 좋아서 기분좋게 식사했습니다 샤리양이 적어서 그랬는지 배부르다고 느끼진 않았습니다', '9']\n","['어랏 처음엔 그냥 먹었는데 날이 갈수록 맛있어지는 맛집인가보네요 적당히 맵고 새콤 달콤한 오이무침 짱 다른 메뉴들도 슬슬 궁금해지네요 딤섬도 그럭저럭 좋았구요 저랑 간이 잘 맞는 식당이에요', '13']\n","['서비스최악 기다리는데 안내도 없고 호일위에 음식만 덩그러니 올려놓고 말도 없이감 분위기도 별로 팔에 문신그려진 아저씨들 옴 맛은 왜 특별한지 모르겠는 상상가는 맛 다신안감', '17']\n","['오포리 근처 숯불구이 장어 전문점인데 장어가 진짜 크고 실하다 숯불에 구워 고소하고 부드러운데 느끼함은 쏙 빠진 장어가 진짜 맛있다 찬은 상당히 간단하고 거의 장어에만 집중하는 곳 아주머니가 잘 구워주시고 둘이 키로에 그람 추가하니 배 부르다 성인 둘이면 일키로만 먹어도 되지만 맛있어서 과식 숯불구이 장어집 중에선 아마도 여기가 가장 낫지 않을까 싶음', '17']\n"]}],"source":["print(data_list[0])\n","print(data_list[6000])\n","print(data_list[12000])\n","print(data_list[18000])\n","print(data_list[24000])\n","print(data_list[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-NexpYd_es_d"},"outputs":[],"source":["#train \u0026 test 데이터로 나누기\n","from sklearn.model_selection import train_test_split\n","                                                         \n","dataset_train, dataset_test = train_test_split(data_list, test_size=0.25, random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1675823445661,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"WobUXzvAdTkU","outputId":"fd8b9454-2b01-4c96-fbad-74d81fb8a4b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["18588\n","6197\n"]}],"source":["print(len(dataset_train))\n","print(len(dataset_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejf0cvetdTl_"},"outputs":[],"source":["# BERT 모델에 들어가기 위한 dataset을 만들어주는 클래스\n","class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n","                 pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fAbXUDGSdToA"},"outputs":[],"source":["# Setting parameters\n","#위 코드는 BERT 모델의 토큰화 및 학습에 사용할 파라미터로, 숫자를 조정해도 된다.\n","\n","max_len = 64\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 10\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1675823448780,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"UBYvXl7_dTr2","outputId":"581ef6d9-dcad-44b0-f09b-9bd72c5fc661"},"outputs":[{"name":"stdout","output_type":"stream","text":["using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"]}],"source":["#토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"acOpXHxodTt-"},"outputs":[],"source":["# 한편 토큰화 \u0026 패딩을 거치면 데이터는 다음과 같은 형식을 갖게 된다.\n","data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n","data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1675823457320,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"kg48PLNVdTv5","outputId":"60324566-639b-4567-f9f3-c9a3bd1aa563"},"outputs":[{"data":{"text/plain":["(array([   2, 1875, 6193, 4207, 7795, 4384, 7096,  517, 5330, 5591, 7018,\n","        6553, 3924, 2269, 6999, 2623, 5778, 4354, 4955, 5415, 5354, 7096,\n","        4626, 7217, 7782, 6705, 5439, 1875, 6193, 6896, 1682, 3372, 7096,\n","         745, 7828, 1022, 6957, 6999, 4299, 5859, 1458, 1967, 7141, 7330,\n","        3192, 5330, 1698, 1267, 5889, 4128, 5330, 3094, 5439, 3198, 7794,\n","        1967, 7354, 7139,    3,    1,    1,    1,    1,    1], dtype=int32),\n"," array(59, dtype=int32),\n"," array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","       dtype=int32),\n"," 5)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["data_train[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1675823457321,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"pspRQsNbdTyB","outputId":"fcaa7c2e-6ad3-4edc-c44f-a1da26c58fa9"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["# 아래 코드를 실행하여 torch 형식의 dataset을 만들어준다\n","train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n","test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQWzB2otdT0I"},"outputs":[],"source":["# KoBERT 학습모델 만들기\n","# 학습시킬 KoBERT 모델을 만들어야 하는데, 아래 코드에서 다중분류할 클래스 수 만큼 num_classes 변수를 수정해주어야 한다. 17가지의 class를 분류하기 때문에 17로 입력"]},{"cell_type":"markdown","metadata":{"id":"4B1rMBpBWiMm"},"source":["## 모델구성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E4_iqfPNdT15"},"outputs":[],"source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=18,   ##클래스 수 조정##\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","      #valid_length까지만 1, 나머지는 0으로 mask를 생성\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        #pooler는 CLS토큰에 대한 임베딩의 결과, 단순히 첫번째 토큰에 대한 결과가 아니라 문맥을 알아내기 위한 추가 layer를 통과한다.(아마도?)\n","        #임베딩의 결과에 linear layer를 통과시켜서 classification을 진행한다.\n","        # print(pooler.shape) batchsize * 768\n","\n","        #_는 64개(max_length)의 모든 토큰에 대한 임베딩의 결과\n","        #단어 임베딩을 알고 싶을 때 사용할 수 있다.\n","        #_의 첫번째 값과 pooler와는 다른 값을 가지고 있는데 pooler는 _의 첫번째 값의 추가적으로 한번더 과정을 거친다.\n","        #print(_.shape) batchsize * max_len * 768\n","\n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out) #batchsize * num_classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oMrC1fyddT4B"},"outputs":[],"source":["model = BERTClassifier(bertmodel,  dr_rate=0.5) #.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mUBwFV2LdT5l"},"outputs":[],"source":["# Prepare optimizer and schedule (linear warmup and decay)\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sEbbz0EEfS35"},"outputs":[],"source":["optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UHkHiZhlfS5n"},"outputs":[],"source":["t_total = len(train_dataloader) * num_epochs\n","warmup_step = int(t_total * warmup_ratio)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y0urQgQSfS7l"},"outputs":[],"source":["scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PzFBSQ_JfS9i"},"outputs":[],"source":["# 정확도 측정을 위한 함수 정의\n","def calc_accuracy(X,Y):\n","    max_vals, max_indices = torch.max(X, 1)\n","    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","    return train_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1675823460527,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"zgHoYAaDfS_b","outputId":"79864e41-9cf9-4d8f-e460-f45ce33e9db0"},"outputs":[{"data":{"text/plain":["\u003ctorch.utils.data.dataloader.DataLoader at 0x7f5379d61e20\u003e"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["train_dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-0OPFtENfTBA"},"outputs":[],"source":[" # KoBERT 모델 학습시키기\n","  # 학습 데이터셋과 학습 모델 준비가 다 끝났다면 이제 아래 코드 실행을 통해 KoBERT 모델을 학습시켜준다."]},{"cell_type":"markdown","metadata":{"id":"Rz6AFwA3WfJI"},"source":["## 모델학습 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WWpR8R81fTC_"},"outputs":[],"source":["from tqdm.notebook import tqdm\n","train_history=[]\n","test_history=[]\n","loss_history=[]\n","\n","for e in range(num_epochs):\n","    train_acc = 0.0\n","    test_acc = 0.0\n","    model.train()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n","        optimizer.zero_grad()\n","        token_ids = token_ids.long() #.to(device)\n","        segment_ids = segment_ids.long() #.to(device)\n","        valid_length= valid_length\n","        label = label.long() #.to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","\n","        #print(label.shape,out.shape)\n","        loss = loss_fn(out, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()  # Update learning rate schedule\n","        train_acc += calc_accuracy(out, label)\n","        if batch_id % log_interval == 0:\n","            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n","            train_history.append(train_acc / (batch_id+1)) #train_acc 저장\n","            loss_history.append(loss.data.cpu().numpy())   #train_loss 저장\n","    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n","    train_history.append(train_acc / (batch_id+1))\n","    \n","    model.eval()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n","        token_ids = token_ids.long() #.to(device)\n","        segment_ids = segment_ids.long() #.to(device)\n","        valid_length= valid_length\n","        label = label.long() #.to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        test_acc += calc_accuracy(out, label)\n","    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n","    test_history.append(test_acc / (batch_id+1)) #test_acc 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":367,"status":"ok","timestamp":1675781155215,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"td9llWrifTEs","outputId":"75052534-b156-4507-990b-1bdf40f3b7f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"]}],"source":["#토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2603,"status":"ok","timestamp":1675750851419,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"vCHUJUuNfTL6","outputId":"4c1d6f8c-c043-43a5-8347-06ae0f895da8"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# 모델저장\n","# 파이토치사용시\n","from transformers import BertForMaskedLM #파이토치\n","torch_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","\n","# 모델 클래스 이름.from_pretrained(저장된 디렉토리) 형태\n","# torch.save(torch_model,f'/content/drive/MyDrive/Colab Notebooks/Save_data/model{model_num}.pt')  # 전체 모델 저장\n","torch_model.save_pretrained('/content/drive/MyDrive/Colab Notebooks/Save_data/model4.pt') # 파이토치 기반 모델"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iSIDs769umNC"},"outputs":[],"source":["# 모델불러오기\n","from transformers import BertForMaskedLM #파이토치\n","modelload = BertForMaskedLM.from_pretrained('/content/drive/MyDrive/Colab Notebooks/Save_data/model2(10epochs,train_acc:0.91,test_acc:0.70).pt')"]},{"cell_type":"markdown","metadata":{"id":"hXxZ-gieu1xX"},"source":["## predict 함수 방법1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ACKGNqIfTIN"},"outputs":[],"source":["def predict(predict_sentence):\n","\n","    data = [predict_sentence, '0']\n","    dataset_another = [data]\n","\n","    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n","    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n","    \n","    modelload.eval()\n","\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","        token_ids = token_ids.long() #.to(device)\n","        segment_ids = segment_ids.long() #.to(device)\n","\n","        valid_length= valid_length\n","        label = label.long() #.to(device)\n","\n","        out = model(token_ids, valid_length, segment_ids)\n","\n","\n","        test_eval=[]\n","        for i in out:\n","            logits=i\n","            logits = logits.detach().cpu().numpy()\n","\n","            if np.argmax(logits) == 1:\n","                test_eval.append(\"곱창\")\n","            elif np.argmax(logits) == 2:\n","                test_eval.append(\"국수\")\n","            elif np.argmax(logits) == 3:\n","                test_eval.append(\"돈카츠\")\n","            elif np.argmax(logits) == 4:\n","                test_eval.append(\"디저트\")\n","            elif np.argmax(logits) == 5:\n","                test_eval.append(\"라멘\")\n","            elif np.argmax(logits) == 6:\n","                test_eval.append(\"버거\")\n","            elif np.argmax(logits) == 7:\n","                test_eval.append(\"베이커리\")\n","            elif np.argmax(logits) == 8:\n","                test_eval.append(\"분식\")\n","            elif np.argmax(logits) == 9:\n","                test_eval.append(\"스시\")\n","            elif np.argmax(logits) == 10:\n","                test_eval.append(\"아시아음식\")\n","            elif np.argmax(logits) == 11:\n","                test_eval.append(\"양식\")\n","            elif np.argmax(logits) == 12:\n","                test_eval.append(\"전골\")\n","            elif np.argmax(logits) == 13:\n","                test_eval.append(\"중식\")\n","            elif np.argmax(logits) == 14:\n","                test_eval.append(\"치킨\")\n","            elif np.argmax(logits) == 15:\n","                test_eval.append(\"타코\")\n","            elif np.argmax(logits) == 16:\n","                test_eval.append(\"한식\")\n","            elif np.argmax(logits) == 17:\n","                test_eval.append(\"해산물\")\n","\n","        print(\"\u003e\u003e 입력하신 내용을 종합해 분석결과, \" +test_eval[0]+ \"이(가) 종류의 음식들은 어떠신가요?.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3mdHmAR9kiw2"},"outputs":[],"source":["# 새로운 문장 테스트\n","# 마지막 단계로, 앞에서 훈련시킨 KoBERT 모델에 새로운 문장을 넣어, 분류를 잘 하는지 테스트 해보려고 한다.\n","\n","# 새로운 문장 역시 토크화 과정을 시켜줌"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1336,"status":"ok","timestamp":1675824139486,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"xwQ3lAZqWApv","outputId":"35ece4d0-f280-4cc1-ffcf-53662a05ce98"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003e\u003e 입력하신 내용을 종합해 분석결과, 타코이(가) 종류의 음식들은 어떠신가요?.\n"]}],"source":["predict('남부 유럽의 전통적인 특색을 살리면서도 너무 자극적이지 않은 음식이 생각납니다. 해안 음식이 들어가지 않고 육지 음식이 메인이면서도 너무 묵직하지 않고 가벼운 느낌이 나면 좋을 것 같아요. 유럽 특유의 향신료가 가볍게 들어가는 것은 좋지만 너무 진하여 음식 본유의 맛이 깨지지 않는 음식으로 부탁합니다.')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1328,"status":"ok","timestamp":1675824252982,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"SEo5Teyl6JIV","outputId":"233d0d95-eff1-40a1-fd83-8efb1c45b693"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["\u003e\u003e 입력하신 내용을 종합해 분석결과, 디저트이(가) 종류의 음식들은 어떠신가요?.\n"]}],"source":["predict('돼지고기 육즙이 가득하고 풍미가 좋으며 신선한 야채들과 고소한 빵과 탄산과 함께 즐기면 좋을만한 음식이 먹고싶군요')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1288,"status":"ok","timestamp":1675824436748,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"hUJYyD8o62eY","outputId":"630d8724-2172-4039-c011-d1d56463de01"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003e\u003e 입력하신 내용을 종합해 분석결과, 디저트이(가) 종류의 음식들은 어떠신가요?.\n"]}],"source":["predict('친구랑 촉촉하고 후루룩먹을 수 있는거 먹고싶어')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1088,"status":"ok","timestamp":1675824456022,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"AZcST1Xn62gT","outputId":"eb26d061-8c2e-416b-931d-972030c12c32"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003e\u003e 입력하신 내용을 종합해 분석결과, 치킨이(가) 종류의 음식들은 어떠신가요?.\n"]}],"source":["predict('입에 넣어서 씹자마자 육즙이 팡팡터지고 씹으면 씹을수록 고소함과 감치맛을 느낄수 있는 음식이 먹고싶어요')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":958,"status":"ok","timestamp":1675824482056,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"iCqicB8q62iC","outputId":"c7ada6b4-ff3a-428c-a47a-9e35bf00f4a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003e\u003e 입력하신 내용을 종합해 분석결과, 스시이(가) 종류의 음식들은 어떠신가요?.\n"]}],"source":["predict('어제 문제를 해결하지 못하여 몹시 지쳤을 때 기운을 낼 수 있을 정도로 든든하고 푸짐하며 얼큰한 음식을 먹고 싶어요')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":730,"status":"ok","timestamp":1675824506108,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"RFISprMr62kC","outputId":"b0201c29-12dc-4135-deca-77f753e8b864"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003e\u003e 입력하신 내용을 종합해 분석결과, 디저트이(가) 종류의 음식들은 어떠신가요?.\n"]}],"source":["predict('시원하고 적당한 음식')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1382,"status":"ok","timestamp":1675824520460,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"T7WmNM0g6JKF","outputId":"15558390-ac34-4c05-c3d6-129a67be665c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003e\u003e 입력하신 내용을 종합해 분석결과, 디저트이(가) 종류의 음식들은 어떠신가요?.\n"]}],"source":["predict('다음 주에 진행할 프로젝트에서 떨지 않을 수 있을 정도로 감동적인 음식을 먹고 싶어요')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":910},"executionInfo":{"elapsed":170219,"status":"error","timestamp":1675823800469,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"7En-X_SFkV9u","outputId":"1b828844-ab13-4562-cd32-50a7917c6a21"},"outputs":[{"name":"stdout","output_type":"stream","text":["생각나는 키워들을 입력하세요.: 여자친구랑 데이트할 때 먹을 음식\n","\u003e\u003e 입력하신 내용을 종합해 분석결과, 디저트이(가) 가장 적합하다고 생각됩니다.\n","\n","\n","생각나는 키워들을 입력하세요.: 매콤하고 칼칼한음식 추천해줘\n","\u003e\u003e 입력하신 내용을 종합해 분석결과, 디저트이(가) 가장 적합하다고 생각됩니다.\n","\n","\n","생각나는 키워들을 입력하세요.: 매운음식\n","\u003e\u003e 입력하신 내용을 종합해 분석결과, 곱창이(가) 가장 적합하다고 생각됩니다.\n","\n","\n","생각나는 키워들을 입력하세요.: 해장하기 좋은 음식추천해줘\n","\u003e\u003e 입력하신 내용을 종합해 분석결과, 디저트이(가) 가장 적합하다고 생각됩니다.\n","\n","\n","생각나는 키워들을 입력하세요.: 맛있는음식 추천해줘\n","\u003e\u003e 입력하신 내용을 종합해 분석결과, 디저트이(가) 가장 적합하다고 생각됩니다.\n","\n","\n","생각나는 키워들을 입력하세요.: 코딩할때 먹을 음식 추천해줘\n","\u003e\u003e 입력하신 내용을 종합해 분석결과, 디저트이(가) 가장 적합하다고 생각됩니다.\n","\n","\n","생각나는 키워들을 입력하세요.: 한식이 먹고싶어\n","\u003e\u003e 입력하신 내용을 종합해 분석결과, 디저트이(가) 가장 적합하다고 생각됩니다.\n","\n","\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-46-4c540fa9fc2d\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 4\u001b[0;31m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"생각나는 키워들을 입력하세요.: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--\u003e 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}],"source":["#질문 무한반복하기! 0 입력시 종료\n","end = 1\n","while end == 1 :\n","    sentence = input(\"생각나는 키워들을 입력하세요.: \")\n","    if sentence == 0 :\n","        break\n","    predict(sentence)\n","    print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"xZS_wdZNu7nE"},"source":["## predict 함수 방법2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7AEzHbbPkV_e"},"outputs":[],"source":["def softmax(vals, idx):\n","    valscpu = vals.cpu().detach().squeeze(0)\n","    a = 0\n","    for i in valscpu:\n","        a += np.exp(i)\n","    return ((np.exp(valscpu[idx]))/a).item() * 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R-JhBAHSkWBP"},"outputs":[],"source":["# cate = [\"정치\",\"경제\",\"사회\", \"생활/문화\",\"세계\",\"기술/IT\", \"연예\", \"스포츠\"]\n","# tmp = [\"아이패드 프로에 m1칩 탑재\"]\n","# transform = nlp.data.BERTSentenceTransform(tok, max_len, pad=True, pair=False)\n","# tokenized = transform(tmp)\n","\n","# result = model(torch.tensor([tokenized[0]]).to(device), [tokenized[1]], torch.tensor(tokenized[2]).to(device))\n","# idx = result.argmax().cpu().item()\n","# print(\"뉴스의 카테고리는:\", cate[idx])\n","# print(\"신뢰도는:\", \"{:.2f}%\".format(softmax(result,idx)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DXwm8-ECkWC8"},"outputs":[],"source":["# torch.save(model.state_dict(), \"news.pt\")\n","# modelload = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n","# modelload.load_state_dict(torch.load(\"news.pt\", device))\n","# modelload.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XZLbf8onvOAT"},"outputs":[],"source":["def testModel(model, seq):\n","    cate = [\"곱창\",\"국수\",\"돈카츠\", \"디저트\",\"라멘\",\"버거\", \"베이커리\", \"분식\", \"스시\", \"아시아음식\", \"양식\", \"전골\", \"중식\", \"치킨\", \"타코\", \"한식\", \"해산물\"]\n","    tmp = [seq]\n","    transform = nlp.data.BERTSentenceTransform(tok, max_len, pad=True, pair=False)\n","    tokenized = transform(tmp)\n","\n","    modelload.eval()\n","    # result = model(torch.tensor([tokenized[0]]).to(device), [tokenized[1]], torch.tensor(tokenized[2]).to(device))\n","    result = model(torch.tensor([tokenized[0]]), [tokenized[1]], [tokenized[1]])\n","    idx = result.argmax().cpu().item()\n","    print(\"뉴스의 카테고리는:\", cate[idx])\n","    print(\"신뢰도는:\", \"{:.2f}%\".format(softmax(result,idx)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":325},"executionInfo":{"elapsed":3,"status":"error","timestamp":1675824330584,"user":{"displayName":"JIN","userId":"06208610298616237541"},"user_tz":-540},"id":"uQwFu5OZvOCC","outputId":"d8a710e7-1597-4bdc-8dad-687caca16ea8"},"outputs":[{"ename":"AttributeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-65-cd4b97d3183f\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mtestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"쫀득하고 탱탱한 면빨이 있는 음식추천해줘\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m\u003cipython-input-64-db34ea67b682\u003e\u001b[0m in \u001b[0;36mtestModel\u001b[0;34m(model, seq)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodelload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# result = model(torch.tensor([tokenized[0]]).to(device), [tokenized[1]], torch.tensor(tokenized[2]).to(device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 9\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"뉴스의 카테고리는:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-28-a2a2927b2f80\u003e\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, valid_length, segment_ids)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#print(_.shape) batchsize * max_len * 768\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 34\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'long'"]}],"source":["testModel(model, \"쫀득하고 탱탱한 면빨이 있는 음식추천해줘\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n0Vk4UXz0ry5"},"outputs":[],"source":["def softmax(vals, idx):\n","    valscpu = vals.cpu().detach().squeeze(0)\n","    a = 0\n","    for i in valscpu:\n","        a += np.exp(i)\n","    return ((np.exp(valscpu[idx]))/a).item() * 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ohmx5hTp0r0q"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMJTxsU6rK/q52h11d9JuVa","machine_shape":"hm","name":"","provenance":[{"file_id":"1kLV9hBBx4XHVvWmtVrfz9Dde8QXmbV_q","timestamp":1675830986990}],"version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}